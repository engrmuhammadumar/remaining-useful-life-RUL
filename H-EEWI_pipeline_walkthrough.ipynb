{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b82ab640",
   "metadata": {},
   "source": [
    "\n",
    "# H-EEWI (Hierarchical Energy–Entropy Wear Index) — Step-by-Step Notebook\n",
    "\n",
    "This notebook walks you through a **divide & conquer** implementation for the PHM 2010 Milling dataset:\n",
    "\n",
    "**What you'll do:**\n",
    "1. Configure paths & parameters\n",
    "2. Load data (per-cutter) and sanity-check shapes\n",
    "3. Window the signals (robust to short series)\n",
    "4. Compute per-band EEWI and fuse to H-EEWI\n",
    "5. (Optional) Monotone smoothing of H-EEWI vs time\n",
    "6. Learn global monotone mappings: `H-EEWI → wear fraction s → RUL`\n",
    "7. Evaluate LOTO (leave-one-tool-out) folds over `TRAIN_CUTTERS`\n",
    "8. Train on all train cutters, infer on `TEST_CUTTERS`\n",
    "9. Add **bootstrap**-based uncertainty (two options)\n",
    "\n",
    "> **Tip:** Run each cell sequentially. Edit the `BASE` path in the Config cell to match your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39e05e",
   "metadata": {},
   "source": [
    "## 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3afb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If something is missing in your environment, uncomment the line below to install.\n",
    "# !pip install numpy pandas scipy scikit-learn tqdm matplotlib\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, glob, math, json\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import welch\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make plots render inline\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d406324",
   "metadata": {},
   "source": [
    "## 2) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    # EDIT THIS PATH to your PHM 2010 Milling base directory:\n",
    "    BASE: str = r\"E:\\Collaboration Work\\With Farooq\\phm dataset\\PHM Challange 2010 Milling\"\n",
    "    # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "    TRAIN_CUTTERS: Tuple[str, ...] = (\"c1\", \"c4\", \"c6\")\n",
    "    TEST_CUTTERS: Tuple[str, ...]  = (\"c2\", \"c3\", \"c5\")\n",
    "\n",
    "    # Sampling & windowing\n",
    "    fs: float = 50000.0      # Hz\n",
    "    window_sec: float = 0.1  # 100 ms windows\n",
    "    hop_sec: float = 0.05    # 50% overlap\n",
    "\n",
    "    # Frequency bands (adapt to your sensors)\n",
    "    bands: Tuple[Tuple[float, float], ...] = (\n",
    "        (500.0, 2000.0),    # Low\n",
    "        (2000.0, 6000.0),   # Mid\n",
    "        (6000.0, 20000.0),  # High\n",
    "    )\n",
    "\n",
    "    # EEWI mix between energy and entropy: alpha * log(E) + (1-alpha) * H\n",
    "    alpha_energy: float = 0.6\n",
    "\n",
    "    # Fusion weights; if None, we learn simple convex weights on a small grid\n",
    "    fuse_weights: Optional[Tuple[float, float, float]] = None\n",
    "\n",
    "    # Bootstrap settings\n",
    "    bootstrap_B: int = 150\n",
    "    entropy_bootstrap_sigma: float = 0.05  # multiplicative lognormal noise on PSD bins\n",
    "    window_bootstrap: bool = True          # also do window-level bootstrap\n",
    "\n",
    "    # Smoothing / monotonic post-projection for H-EEWI curve per tool\n",
    "    isotonic_smooth_heewi: bool = True\n",
    "\n",
    "    # Output directory for figures & JSON\n",
    "    outdir: str = \"./heewi_outputs\"\n",
    "\n",
    "CFG = Config()\n",
    "CFG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084acde",
   "metadata": {},
   "source": [
    "## 3) Small utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22970d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def normalize_prob(p: np.ndarray, axis: int = -1, eps: float = 1e-12) -> np.ndarray:\n",
    "    s = p.sum(axis=axis, keepdims=True)\n",
    "    return p / np.maximum(s, eps)\n",
    "\n",
    "def spectral_entropy(psd_band: np.ndarray, axis: int = -1, eps: float = 1e-12) -> np.ndarray:\n",
    "    \"\"\"Shannon spectral entropy (ln), normalized to [0,1] by dividing by log(N).\"\"\"\n",
    "    p = normalize_prob(psd_band, axis=axis)\n",
    "    H = -(p * np.log(np.maximum(p, eps))).sum(axis=axis)\n",
    "    H_norm = H / np.log(psd_band.shape[axis])\n",
    "    return H_norm\n",
    "\n",
    "def band_mask(freqs: np.ndarray, f_lo: float, f_hi: float) -> np.ndarray:\n",
    "    return (freqs >= f_lo) & (freqs < f_hi)\n",
    "\n",
    "def compute_welch_psd(x: np.ndarray, fs: float, nperseg: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    freqs, Pxx = welch(x, fs=fs, nperseg=nperseg, noverlap=nperseg//2,\n",
    "                       detrend='constant', return_onesided=True, scaling='density')\n",
    "    return freqs, Pxx\n",
    "\n",
    "def aggregate_multichannel_psd(X: np.ndarray, fs: float, nperseg: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Aggregate PSD across channels by summing spectra.\"\"\"\n",
    "    freqs, psd0 = compute_welch_psd(X[:, 0], fs, nperseg)\n",
    "    psd_sum = psd0.copy()\n",
    "    for c in range(1, X.shape[1]):\n",
    "        _, psd_c = compute_welch_psd(X[:, c], fs, nperseg)\n",
    "        psd_sum += psd_c\n",
    "    return freqs, psd_sum\n",
    "\n",
    "def eewi_from_psd(freqs: np.ndarray, psd: np.ndarray,\n",
    "                  bands: List[Tuple[float, float]], alpha: float) -> np.ndarray:\n",
    "    vals = []\n",
    "    for (f_lo, f_hi) in bands:\n",
    "        m = band_mask(freqs, f_lo, f_hi)\n",
    "        if not np.any(m):\n",
    "            vals.append(np.nan); continue\n",
    "        psd_band = psd[m]\n",
    "        E = np.sum(psd_band)\n",
    "        H = spectral_entropy(psd_band[None, :], axis=-1)[0]\n",
    "        vals.append(alpha * np.log(max(E, 1e-12)) + (1.0 - alpha) * H)\n",
    "    return np.array(vals)\n",
    "\n",
    "def fuse_hierarchical(eewi_per_band: np.ndarray, weights: Optional[np.ndarray] = None) -> float:\n",
    "    x = eewi_per_band.copy()\n",
    "    finite = np.isfinite(x)\n",
    "    if not np.any(finite):\n",
    "        return np.nan\n",
    "    x = x[finite]\n",
    "    if weights is None:\n",
    "        w = np.ones_like(x) / len(x)\n",
    "    else:\n",
    "        w = weights[finite]\n",
    "        w = np.maximum(w, 0)\n",
    "        w = w / w.sum() if w.sum() > 0 else np.ones_like(x) / len(x)\n",
    "    return float(np.dot(w, x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a62e6c",
   "metadata": {},
   "source": [
    "## 4) Dataset loader (adapt to your files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22393d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PHM2010Loader:\n",
    "    def __init__(self, base: str, channel_cols: Optional[List[str]] = None):\n",
    "        self.base = base\n",
    "        self.channel_cols = channel_cols  # e.g., [\"AE\", \"Vx\", \"Vy\", \"Fx\", \"Fy\", \"Fz\"]\n",
    "\n",
    "    def list_files(self, cutter: str) -> List[str]:\n",
    "        pattern = os.path.join(self.base, cutter, \"*.csv\")\n",
    "        files = sorted(glob.glob(pattern))\n",
    "        if not files:\n",
    "            pattern = os.path.join(self.base, cutter, \"**\", \"*.csv\")\n",
    "            files = sorted(glob.glob(pattern, recursive=True))\n",
    "        return files\n",
    "\n",
    "    def load_cutter(self, cutter: str) -> pd.DataFrame:\n",
    "        files = self.list_files(cutter)\n",
    "        if not files:\n",
    "            raise FileNotFoundError(f\"No CSV files found for cutter {cutter} under {self.base}\")\n",
    "        dfs = [pd.read_csv(fp) for fp in files]\n",
    "        df_all = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "        if self.channel_cols is not None:\n",
    "            missing = [c for c in self.channel_cols if c not in df_all.columns]\n",
    "            if missing:\n",
    "                raise KeyError(f\"Missing channels in data: {missing}\")\n",
    "            return df_all[self.channel_cols]\n",
    "        return df_all.select_dtypes(include=[np.number])  # default: all numeric\n",
    "\n",
    "# Quick listing to confirm files exist\n",
    "loader = PHM2010Loader(CFG.BASE, channel_cols=None)  # set your channel list if needed\n",
    "for c in CFG.TRAIN_CUTTERS + CFG.TEST_CUTTERS:\n",
    "    print(c, len(loader.list_files(c)), \"file(s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7266a",
   "metadata": {},
   "source": [
    "## 5) Windowing (robust to short series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f484fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class Windows:\n",
    "    X: np.ndarray        # [W, T, C]\n",
    "    t_index: np.ndarray  # [W]\n",
    "\n",
    "def make_windows(X: np.ndarray, fs: float, window_sec: float, hop_sec: float) -> Windows:\n",
    "    \"\"\"Slice multichannel signal X [N, C] into overlapping windows.\n",
    "    Guarantees at least one window by zero-padding when N < T.\n",
    "    \"\"\"\n",
    "    N, C = X.shape\n",
    "    T = int(round(window_sec * fs))\n",
    "    H = int(round(hop_sec * fs))\n",
    "    if T <= 0 or H <= 0:\n",
    "        raise ValueError(\"window_sec and hop_sec must be positive\")\n",
    "\n",
    "    if N < T:\n",
    "        Xp = np.zeros((T, C), dtype=float)\n",
    "        Xp[:N, :] = X\n",
    "        return Windows(X=Xp[None, ...], t_index=np.array([0], dtype=int))\n",
    "\n",
    "    idx = []\n",
    "    for start in range(0, max(1, N - T + 1), H):\n",
    "        stop = start + T\n",
    "        if stop <= N:\n",
    "            idx.append((start, stop))\n",
    "\n",
    "    W = len(idx)\n",
    "    if W == 0:\n",
    "        a = max(0, N - T); b = N\n",
    "        return Windows(X=X[a:b, :][None, ...], t_index=np.array([0], dtype=int))\n",
    "\n",
    "    Xw = np.zeros((W, T, C), dtype=float)\n",
    "    for i, (a, b) in enumerate(idx):\n",
    "        Xw[i] = X[a:b, :]\n",
    "    return Windows(X=Xw, t_index=np.arange(W, dtype=int))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b36370",
   "metadata": {},
   "source": [
    "## 6) Compute per-window EEWI and fuse to H-EEWI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class HEewiResult:\n",
    "    heewi: np.ndarray               # [W]\n",
    "    heewi_per_band: np.ndarray      # [W, K]\n",
    "    freqs_example: np.ndarray       # [F]\n",
    "\n",
    "def compute_heewi_for_windows(wins: Windows, fs: float,\n",
    "                              bands: List[Tuple[float, float]], alpha: float,\n",
    "                              fuse_weights: Optional[np.ndarray] = None,\n",
    "                              isotonic_smooth: bool = True) -> HEewiResult:\n",
    "    W, T, C = wins.X.shape\n",
    "    nperseg = min(1024, T)\n",
    "    K = len(bands)\n",
    "    heewi_per_band = np.zeros((W, K), dtype=float)\n",
    "    heewi = np.zeros(W, dtype=float)\n",
    "    freqs_example = None\n",
    "\n",
    "    for i in tqdm(range(W), desc=\"EEWI per window\"):\n",
    "        Xi = wins.X[i]\n",
    "        freqs, psd_sum = aggregate_multichannel_psd(Xi, fs, nperseg)\n",
    "        if freqs_example is None:\n",
    "            freqs_example = freqs\n",
    "        eewi_k = eewi_from_psd(freqs, psd_sum, bands, alpha)\n",
    "        heewi_per_band[i] = eewi_k\n",
    "        heewi[i] = fuse_hierarchical(eewi_k, weights=fuse_weights)\n",
    "\n",
    "    if isotonic_smooth and W >= 1:\n",
    "        iso = IsotonicRegression(increasing=True, out_of_bounds=\"clip\")\n",
    "        heewi = iso.fit_transform(np.arange(W), heewi)\n",
    "\n",
    "    return HEewiResult(heewi=heewi, heewi_per_band=heewi_per_band, freqs_example=freqs_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17af26ec",
   "metadata": {},
   "source": [
    "## 7) Plotting helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06cf609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_heewi_curve(t_idx: np.ndarray, heewi: np.ndarray, title: str, path: str):\n",
    "    plt.figure()\n",
    "    plt.plot(t_idx, heewi)\n",
    "    plt.xlabel(\"Window index\")\n",
    "    plt.ylabel(\"H-EEWI\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "def plot_rul_with_pi(t_idx: np.ndarray, rul_pred: np.ndarray, rul_true: Optional[np.ndarray],\n",
    "                     lo: Optional[np.ndarray], hi: Optional[np.ndarray], title: str, path: str):\n",
    "    plt.figure()\n",
    "    if lo is not None and hi is not None:\n",
    "        plt.fill_between(t_idx, lo, hi, alpha=0.3, label=\"PI\")\n",
    "    plt.plot(t_idx, rul_pred, label=\"Pred RUL\")\n",
    "    if rul_true is not None:\n",
    "        plt.plot(t_idx, rul_true, linestyle='--', label=\"True RUL\")\n",
    "    plt.xlabel(\"Window index\")\n",
    "    plt.ylabel(\"RUL (windows)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=160)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d36bc0f",
   "metadata": {},
   "source": [
    "## 8) Prepare a single cutter → windows → H-EEWI (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0139ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_series_for_cutter(df: pd.DataFrame, fs: float, window_sec: float, hop_sec: float,\n",
    "                              bands: List[Tuple[float, float]], alpha: float,\n",
    "                              fuse_weights: Optional[np.ndarray], iso_smooth: bool):\n",
    "    X = df.to_numpy(dtype=float)\n",
    "    wins = make_windows(X, fs, window_sec, hop_sec)\n",
    "\n",
    "    he = compute_heewi_for_windows(wins, fs, bands, alpha,\n",
    "                                   fuse_weights=fuse_weights, isotonic_smooth=iso_smooth)\n",
    "\n",
    "    W = len(wins.t_index)\n",
    "    rul_true = np.arange(W-1, -1, -1)  # proxy if true labels aren't per-sample\n",
    "    return {\n",
    "        \"heewi\": he.heewi,\n",
    "        \"heewi_per_band\": he.heewi_per_band,\n",
    "        \"t_idx\": wins.t_index,\n",
    "        \"rul_true\": rul_true\n",
    "    }\n",
    "\n",
    "# === Try a single cutter (first TRAIN) ===\n",
    "ensure_dir(CFG.outdir)\n",
    "first_c = CFG.TRAIN_CUTTERS[0]\n",
    "df_demo = loader.load_cutter(first_c)\n",
    "\n",
    "print(f\"{first_c} shape:\", df_demo.shape)\n",
    "WINS = make_windows(df_demo.to_numpy(dtype=float), CFG.fs, CFG.window_sec, CFG.hop_sec)\n",
    "print(\"Windows:\", WINS.X.shape)  # [W, T, C]\n",
    "\n",
    "demo = prepare_series_for_cutter(df_demo, CFG.fs, CFG.window_sec, CFG.hop_sec,\n",
    "                                 list(CFG.bands), CFG.alpha_energy, None, CFG.isotonic_smooth_heewi)\n",
    "\n",
    "plot_heewi_curve(demo[\"t_idx\"], demo[\"heewi\"],\n",
    "                 f\"{first_c} H-EEWI (raw, equal weights)\",\n",
    "                 os.path.join(CFG.outdir, f\"{first_c}_heewi_curve.png\"))\n",
    "\n",
    "print(\"Saved:\", os.path.join(CFG.outdir, f\"{first_c}_heewi_curve.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ecb9a",
   "metadata": {},
   "source": [
    "## 9) Learn simple convex fusion weights over train cutters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39843344",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learn_fuse_weights(series_list: List[Dict]) -> np.ndarray:\n",
    "    \"\"\"Grid-search small convex weights to reduce proxy RUL RMSE.\"\"\"\n",
    "    K = series_list[0][\"heewi_per_band\"].shape[1]\n",
    "    for s in series_list:\n",
    "        if np.any(~np.isfinite(s[\"heewi_per_band\"])):\n",
    "            return np.ones(K) / K\n",
    "\n",
    "    step = 0.25\n",
    "    ws = np.arange(0, 1+1e-9, step)\n",
    "    grid = []\n",
    "    for a in ws:\n",
    "        for b in ws:\n",
    "            c = 1 - a - b\n",
    "            if c < -1e-9: \n",
    "                continue\n",
    "            c = max(0.0, c)\n",
    "            ssum = a + b + c\n",
    "            grid.append(np.array([a, b, c]) / (ssum if ssum>0 else 1.0))\n",
    "\n",
    "    best_rmse = float('inf'); best_w = np.ones(K)/K\n",
    "    for w in grid:\n",
    "        rmses = []\n",
    "        for s in series_list:\n",
    "            heewi = (s[\"heewi_per_band\"] @ w)\n",
    "            iso_s = IsotonicRegression(increasing=True, out_of_bounds=\"clip\")\n",
    "            s_frac = np.linspace(0, 1, len(s[\"t_idx\"]))\n",
    "            iso_s.fit(heewi, s_frac)\n",
    "            s_hat = iso_s.predict(heewi)\n",
    "            rul_hat = (1 - s_hat) * (len(s[\"t_idx\"]) - 1)\n",
    "            rmses.append(mean_squared_error(s[\"rul_true\"], rul_hat, squared=False))\n",
    "        rm = float(np.mean(rmses))\n",
    "        if rm < best_rmse:\n",
    "            best_rmse, best_w = rm, w\n",
    "    return best_w\n",
    "\n",
    "# Build per-cutter series for all TRAIN_CUTTERS (equal weights first)\n",
    "train_series = []\n",
    "for c in CFG.TRAIN_CUTTERS:\n",
    "    df = loader.load_cutter(c)\n",
    "    s = prepare_series_for_cutter(df, CFG.fs, CFG.window_sec, CFG.hop_sec,\n",
    "                                  list(CFG.bands), CFG.alpha_energy, None, CFG.isotonic_smooth_heewi)\n",
    "    train_series.append(s)\n",
    "print(\"Prepared\", len(train_series), \"train cutters.\")\n",
    "\n",
    "# Learn or set fuse weights\n",
    "if CFG.fuse_weights is None:\n",
    "    w_fuse = learn_fuse_weights(train_series)\n",
    "else:\n",
    "    w_fuse = np.array(CFG.fuse_weights, dtype=float)\n",
    "w_fuse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e8940",
   "metadata": {},
   "source": [
    "## 10) Recompute H-EEWI with learned fusion weights (and smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67388e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, s in enumerate(train_series):\n",
    "    heewi = (s[\"heewi_per_band\"] @ w_fuse)\n",
    "    if CFG.isotonic_smooth_heewi:\n",
    "        iso = IsotonicRegression(increasing=True, out_of_bounds=\"clip\")\n",
    "        heewi = iso.fit_transform(np.arange(len(heewi)), heewi)\n",
    "    s[\"heewi\"] = heewi\n",
    "    c = CFG.TRAIN_CUTTERS[idx]\n",
    "    plot_heewi_curve(s[\"t_idx\"], s[\"heewi\"], f\"{c} H-EEWI (fused)\", os.path.join(CFG.outdir, f\"{c}_heewi_curve_fused.png\"))\n",
    "    print(\"Saved:\", os.path.join(CFG.outdir, f\"{c}_heewi_curve_fused.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a7444",
   "metadata": {},
   "source": [
    "## 11) Fit global monotone mappings: H-EEWI→s and s→RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_global_normalization(train_heewi: np.ndarray, train_time_frac: np.ndarray) -> IsotonicRegression:\n",
    "    iso = IsotonicRegression(increasing=True, y_min=0.0, y_max=1.0, out_of_bounds=\"clip\")\n",
    "    iso.fit(train_heewi, train_time_frac)\n",
    "    return iso\n",
    "\n",
    "def fit_global_rul_mapping(train_s: np.ndarray, train_rul: np.ndarray) -> IsotonicRegression:\n",
    "    iso_dec = IsotonicRegression(increasing=False, out_of_bounds=\"clip\")\n",
    "    iso_dec.fit(train_s, train_rul)\n",
    "    return iso_dec\n",
    "\n",
    "# Pool training\n",
    "train_heewi = np.concatenate([s[\"heewi\"] for s in train_series])\n",
    "train_sfrac = np.concatenate([np.linspace(0, 1, len(s[\"t_idx\"])) for s in train_series])\n",
    "iso_heewi_to_s = fit_global_normalization(train_heewi, train_sfrac)\n",
    "\n",
    "train_s = np.concatenate([iso_heewi_to_s.predict(s[\"heewi\"]) for s in train_series])\n",
    "train_rul = np.concatenate([s[\"rul_true\"] for s in train_series])\n",
    "iso_s_to_rul = fit_global_rul_mapping(train_s, train_rul)\n",
    "\n",
    "print(\"Fitted global monotone mappings.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd110e7",
   "metadata": {},
   "source": [
    "## 12) LOTO evaluation on train cutters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class Metrics:\n",
    "    rmse: float\n",
    "    mae: float\n",
    "    monotonicity: float  # fraction of non-decreasing pairs in H-EEWI\n",
    "\n",
    "def monotone_fraction(x: np.ndarray) -> float:\n",
    "    diffs = np.diff(x)\n",
    "    return float(np.mean(diffs >= -1e-9))\n",
    "\n",
    "def eval_fold(y_true_rul: np.ndarray, y_pred_rul: np.ndarray, heewi_curve: np.ndarray) -> Metrics:\n",
    "    rmse = math.sqrt(mean_squared_error(y_true_rul, y_pred_rul))\n",
    "    mae = mean_absolute_error(y_true_rul, y_pred_rul)\n",
    "    mono = monotone_fraction(heewi_curve)\n",
    "    return Metrics(rmse=rmse, mae=mae, monotonicity=mono)\n",
    "\n",
    "fold_results = {}\n",
    "for heldout_idx, heldout in enumerate(CFG.TRAIN_CUTTERS):\n",
    "    # Train on others\n",
    "    train_tools = [i for i,c in enumerate(CFG.TRAIN_CUTTERS) if c != heldout]\n",
    "    pool_heewi = np.concatenate([train_series[i][\"heewi\"] for i in train_tools])\n",
    "    pool_sfrac = np.concatenate([np.linspace(0, 1, len(train_series[i][\"t_idx\"])) for i in train_tools])\n",
    "\n",
    "    iso_h2s = fit_global_normalization(pool_heewi, pool_sfrac)\n",
    "    s_hat_train = iso_h2s.predict(pool_heewi)\n",
    "\n",
    "    pool_s_all = np.concatenate([iso_h2s.predict(train_series[i][\"heewi\"]) for i in train_tools])\n",
    "    pool_rul_all = np.concatenate([train_series[i][\"rul_true\"] for i in train_tools])\n",
    "    iso_s2r = fit_global_rul_mapping(pool_s_all, pool_rul_all)\n",
    "\n",
    "    # Eval on heldout\n",
    "    s_ho = train_series[heldout_idx]\n",
    "    s_seq = iso_h2s.predict(s_ho[\"heewi\"])\n",
    "    rul_pred = iso_s2r.predict(s_seq)\n",
    "    metrics = eval_fold(s_ho[\"rul_true\"], rul_pred, s_ho[\"heewi\"])\n",
    "\n",
    "    # Plot\n",
    "    plot_rul_with_pi(s_ho[\"t_idx\"], rul_pred, s_ho[\"rul_true\"], None, None,\n",
    "                     title=f\"{heldout} RUL (LOTO)\", path=os.path.join(CFG.outdir, f\"{heldout}_rul_loto.png\"))\n",
    "\n",
    "    fold_results[heldout] = {\"metrics\": asdict(metrics), \"fuse_weights\": w_fuse.tolist()}\n",
    "    print(heldout, metrics)\n",
    "\n",
    "summary = {\n",
    "    \"fuse_weights\": w_fuse.tolist(),\n",
    "    \"folds\": fold_results,\n",
    "    \"RMSE_mean\": float(np.mean([fold_results[c][\"metrics\"][\"rmse\"] for c in fold_results])),\n",
    "    \"MAE_mean\": float(np.mean([fold_results[c][\"metrics\"][\"mae\"] for c in fold_results])),\n",
    "    \"MonotoneFrac_mean\": float(np.mean([fold_results[c][\"metrics\"][\"monotonicity\"] for c in fold_results]))\n",
    "}\n",
    "ensure_dir(CFG.outdir)\n",
    "with open(os.path.join(CFG.outdir, \"summary.json\"), \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(\"Saved:\", os.path.join(CFG.outdir, \"summary.json\"))\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf640cde",
   "metadata": {},
   "source": [
    "## 13) Bootstrap utilities (entropy-level & window-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class BootstrapResult:\n",
    "    rul_lo: np.ndarray\n",
    "    rul_hi: np.ndarray\n",
    "    rul_samples: Optional[np.ndarray] = None\n",
    "\n",
    "def entropy_bootstrap_heewi(wins: Windows, fs: float, bands: List[Tuple[float, float]], alpha: float,\n",
    "                            fuse_weights: Optional[np.ndarray], B: int, sigma: float,\n",
    "                            heewi_iso_smooth: bool = True) -> np.ndarray:\n",
    "    W, T, C = wins.X.shape\n",
    "    nperseg = min(1024, T)\n",
    "    heewi_samples = np.zeros((B, W), dtype=float)\n",
    "\n",
    "    # Precompute PSD caches\n",
    "    cache = []\n",
    "    for i in range(W):\n",
    "        freqs, psd_sum = aggregate_multichannel_psd(wins.X[i], fs, nperseg)\n",
    "        cache.append((freqs, psd_sum))\n",
    "\n",
    "    for b in tqdm(range(B), desc=\"Entropy bootstrap\"):\n",
    "        heewi_b = np.zeros(W, dtype=float)\n",
    "        for i in range(W):\n",
    "            freqs, psd_sum = cache[i]\n",
    "            noise = np.exp(np.random.normal(loc=0.0, scale=sigma, size=psd_sum.shape))\n",
    "            psd_noisy = psd_sum * noise\n",
    "            eewi_k = eewi_from_psd(freqs, psd_noisy, bands, alpha)\n",
    "            heewi_b[i] = fuse_hierarchical(eewi_k, weights=fuse_weights)\n",
    "        if heewi_iso_smooth and W >= 1:\n",
    "            iso = IsotonicRegression(increasing=True, out_of_bounds=\"clip\")\n",
    "            heewi_b = iso.fit_transform(np.arange(W), heewi_b)\n",
    "        heewi_samples[b] = heewi_b\n",
    "    return heewi_samples\n",
    "\n",
    "def window_bootstrap_rul(s_seq: np.ndarray, rul_seq: np.ndarray, B: int,\n",
    "                         q_lo: float = 0.05, q_hi: float = 0.95) -> BootstrapResult:\n",
    "    N = len(s_seq)\n",
    "    rul_samples = np.zeros((B, N), dtype=float)\n",
    "    idx_all = np.arange(N)\n",
    "    for b in range(B):\n",
    "        idx = np.random.choice(idx_all, size=N, replace=True)\n",
    "        iso_b = IsotonicRegression(increasing=False, out_of_bounds=\"clip\")\n",
    "        iso_b.fit(s_seq[idx], rul_seq[idx])\n",
    "        rul_samples[b] = iso_b.predict(s_seq)\n",
    "    lo = np.quantile(rul_samples, q_lo, axis=0)\n",
    "    hi = np.quantile(rul_samples, q_hi, axis=0)\n",
    "    return BootstrapResult(rul_lo=lo, rul_hi=hi, rul_samples=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728fce2e",
   "metadata": {},
   "source": [
    "## 14) Train on all train cutters, infer on TEST_CUTTERS (with PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class TrainedGlobal:\n",
    "    iso_heewi_to_s: IsotonicRegression\n",
    "    iso_s_to_rul: IsotonicRegression\n",
    "    fuse_weights: np.ndarray\n",
    "\n",
    "def train_global_on_all_train(cfg: Config, channel_cols: Optional[List[str]] = None) -> TrainedGlobal:\n",
    "    ensure_dir(cfg.outdir)\n",
    "    loader = PHM2010Loader(cfg.BASE, channel_cols=channel_cols)\n",
    "\n",
    "    # Build train series\n",
    "    series = []\n",
    "    for c in cfg.TRAIN_CUTTERS:\n",
    "        df = loader.load_cutter(c)\n",
    "        s = prepare_series_for_cutter(df, cfg.fs, cfg.window_sec, cfg.hop_sec,\n",
    "                                      list(cfg.bands), cfg.alpha_energy, None, cfg.isotonic_smooth_heewi)\n",
    "        series.append(s)\n",
    "\n",
    "    w_fuse = learn_fuse_weights(series) if cfg.fuse_weights is None else np.array(cfg.fuse_weights)\n",
    "\n",
    "    # Recompute fused curves\n",
    "    for s in series:\n",
    "        heewi = (s[\"heewi_per_band\"] @ w_fuse)\n",
    "        if cfg.isotonic_smooth_heewi:\n",
    "            iso = IsotonicRegression(increasing=True, out_of_bounds=\"clip\")\n",
    "            heewi = iso.fit_transform(np.arange(len(heewi)), heewi)\n",
    "        s[\"heewi\"] = heewi\n",
    "\n",
    "    # Fit global mappings\n",
    "    train_heewi = np.concatenate([s[\"heewi\"] for s in series])\n",
    "    train_sfrac = np.concatenate([np.linspace(0, 1, len(s[\"t_idx\"])) for s in series])\n",
    "    iso_heewi_to_s = fit_global_normalization(train_heewi, train_sfrac)\n",
    "\n",
    "    train_s = np.concatenate([iso_heewi_to_s.predict(s[\"heewi\"]) for s in series])\n",
    "    train_rul = np.concatenate([s[\"rul_true\"] for s in series])\n",
    "    iso_s_to_rul = fit_global_rul_mapping(train_s, train_rul)\n",
    "\n",
    "    return TrainedGlobal(iso_heewi_to_s=iso_heewi_to_s, iso_s_to_rul=iso_s_to_rul, fuse_weights=w_fuse)\n",
    "\n",
    "def predict_for_test_cutters(cfg: Config, tg: TrainedGlobal, channel_cols: Optional[List[str]] = None):\n",
    "    ensure_dir(cfg.outdir)\n",
    "    loader = PHM2010Loader(cfg.BASE, channel_cols=channel_cols)\n",
    "\n",
    "    for c in cfg.TEST_CUTTERS:\n",
    "        df = loader.load_cutter(c)\n",
    "        X = df.to_numpy(dtype=float)\n",
    "        wins = make_windows(X, cfg.fs, cfg.window_sec, cfg.hop_sec)\n",
    "        he = compute_heewi_for_windows(wins, cfg.fs, list(cfg.bands), cfg.alpha_energy,\n",
    "                                       fuse_weights=tg.fuse_weights, isotonic_smooth=cfg.isotonic_smooth_heewi)\n",
    "        s_seq = tg.iso_heewi_to_s.predict(he.heewi)\n",
    "        rul_pred = tg.iso_s_to_rul.predict(s_seq)\n",
    "\n",
    "        # Entropy-bootstrap at EEWI level, propagate to RUL\n",
    "        heewi_samples = entropy_bootstrap_heewi(\n",
    "            wins=wins, fs=cfg.fs, bands=list(cfg.bands), alpha=cfg.alpha_energy,\n",
    "            fuse_weights=tg.fuse_weights, B=cfg.bootstrap_B,\n",
    "            sigma=cfg.entropy_bootstrap_sigma, heewi_iso_smooth=cfg.isotonic_smooth_heewi\n",
    "        )\n",
    "        rul_samples = []\n",
    "        for b in range(heewi_samples.shape[0]):\n",
    "            s_b = tg.iso_heewi_to_s.predict(heewi_samples[b])\n",
    "            rul_b = tg.iso_s_to_rul.predict(s_b)\n",
    "            rul_samples.append(rul_b)\n",
    "        rul_samples = np.stack(rul_samples, axis=0)\n",
    "        lo = np.quantile(rul_samples, 0.05, axis=0)\n",
    "        hi = np.quantile(rul_samples, 0.95, axis=0)\n",
    "\n",
    "        plot_rul_with_pi(wins.t_index, rul_pred, None, lo, hi,\n",
    "                         title=f\"{c} RUL (inference)\",\n",
    "                         path=os.path.join(cfg.outdir, f\"{c}_rul_infer.png\"))\n",
    "\n",
    "        # Save arrays\n",
    "        np.save(os.path.join(cfg.outdir, f\"{c}_rul_pred.npy\"), rul_pred)\n",
    "        np.save(os.path.join(cfg.outdir, f\"{c}_rul_pi_lo.npy\"), lo)\n",
    "        np.save(os.path.join(cfg.outdir, f\"{c}_rul_pi_hi.npy\"), hi)\n",
    "        print(f\"Saved predictions & PI for {c}.\")\n",
    "\n",
    "# === Train+infer ===\n",
    "tg = train_global_on_all_train(CFG, channel_cols=None)\n",
    "predict_for_test_cutters(CFG, tg, channel_cols=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e54b3",
   "metadata": {},
   "source": [
    "## 15) (Optional) End-to-end helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccf88ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_loto_experiments(cfg: Config, channel_cols: Optional[List[str]] = None):\n",
    "    ensure_dir(cfg.outdir)\n",
    "    loader = PHM2010Loader(cfg.BASE, channel_cols=channel_cols)\n",
    "\n",
    "    # Build series\n",
    "    series_by_cutter: Dict[str, Dict] = {}\n",
    "    for c in cfg.TRAIN_CUTTERS:\n",
    "        df = loader.load_cutter(c)\n",
    "        s = prepare_series_for_cutter(df, cfg.fs, cfg.window_sec, cfg.hop_sec,\n",
    "                                      list(cfg.bands), cfg.alpha_energy, None, cfg.isotonic_smooth_heewi)\n",
    "        series_by_cutter[c] = s\n",
    "        plot_heewi_curve(s[\"t_idx\"], s[\"heewi\"], f\"{c} H-EEWI (raw, equal weights)\",\n",
    "                         os.path.join(cfg.outdir, f\"{c}_heewi_curve.png\"))\n",
    "\n",
    "    # Learn or set fusion weights\n",
    "    if cfg.fuse_weights is None:\n",
    "        w_fuse = learn_fuse_weights(list(series_by_cutter.values()))\n",
    "    else:\n",
    "        w_fuse = np.array(cfg.fuse_weights, dtype=float)\n",
    "\n",
    "    # Recompute H-EEWI using learned weights\n",
    "    for c in cfg.TRAIN_CUTTERS:\n",
    "        s = series_by_cutter[c]\n",
    "        heewi = (s[\"heewi_per_band\"] @ w_fuse)\n",
    "        if cfg.isotonic_smooth_heewi:\n",
    "            iso = IsotonicRegression(increasing=True, out_of_bounds=\"clip\")\n",
    "            heewi = iso.fit_transform(np.arange(len(heewi)), heewi)\n",
    "        s[\"heewi\"] = heewi\n",
    "        plot_heewi_curve(s[\"t_idx\"], s[\"heewi\"], f\"{c} H-EEWI (fused)\",\n",
    "                         os.path.join(cfg.outdir, f\"{c}_heewi_curve_fused.png\"))\n",
    "\n",
    "    # LOTO folds\n",
    "    fold_metrics = []\n",
    "    all_results = {}\n",
    "    for heldout in cfg.TRAIN_CUTTERS:\n",
    "        train_tools = [c for c in cfg.TRAIN_CUTTERS if c != heldout]\n",
    "\n",
    "        train_heewi = []\n",
    "        train_sfrac = []\n",
    "        train_s_to_rul_s = []\n",
    "        train_rul = []\n",
    "        for c in train_tools:\n",
    "            s = series_by_cutter[c]\n",
    "            W = len(s[\"t_idx\"])\n",
    "            s_frac = np.linspace(0, 1, W)\n",
    "            train_heewi.append(s[\"heewi\"])\n",
    "            train_sfrac.append(s_frac)\n",
    "            train_s_to_rul_s.append(s_frac)\n",
    "            train_rul.append(s[\"rul_true\"])\n",
    "\n",
    "        train_heewi = np.concatenate(train_heewi)\n",
    "        train_sfrac = np.concatenate(train_sfrac)\n",
    "        train_s_to_rul_s = np.concatenate(train_s_to_rul_s)\n",
    "        train_rul = np.concatenate(train_rul)\n",
    "\n",
    "        iso_heewi_to_s = fit_global_normalization(train_heewi, train_sfrac)\n",
    "        s_hat_train = iso_heewi_to_s.predict(train_heewi)\n",
    "        iso_s_to_rul = fit_global_rul_mapping(train_s_to_rul_s, train_rul)\n",
    "\n",
    "        s_ho = series_by_cutter[heldout]\n",
    "        s_seq = iso_heewi_to_s.predict(s_ho[\"heewi\"])\n",
    "        rul_pred = iso_s_to_rul.predict(s_seq)\n",
    "\n",
    "        # Metrics\n",
    "        rmse = math.sqrt(mean_squared_error(s_ho[\"rul_true\"], rul_pred))\n",
    "        mae = mean_absolute_error(s_ho[\"rul_true\"], rul_pred)\n",
    "        mono = float(np.mean(np.diff(s_ho[\"heewi\"]) >= -1e-9))\n",
    "\n",
    "        # PIs (window-level bootstrap)\n",
    "        if cfg.window_bootstrap:\n",
    "            pi = window_bootstrap_rul(s_seq, rul_pred, B=cfg.bootstrap_B)\n",
    "            lo, hi = pi.rul_lo, pi.rul_hi\n",
    "        else:\n",
    "            lo, hi = None, None\n",
    "\n",
    "        plot_rul_with_pi(s_ho[\"t_idx\"], rul_pred, s_ho[\"rul_true\"], lo, hi,\n",
    "                         title=f\"{heldout} RUL (LOTO)\",\n",
    "                         path=os.path.join(cfg.outdir, f\"{heldout}_rul_loto.png\"))\n",
    "\n",
    "        all_results[heldout] = {\n",
    "            \"metrics\": {\"rmse\": rmse, \"mae\": mae, \"monotonicity\": mono},\n",
    "            \"fuse_weights\": w_fuse.tolist()\n",
    "        }\n",
    "        fold_metrics.append((rmse, mae, mono))\n",
    "\n",
    "    agg = {\n",
    "        \"fuse_weights\": w_fuse.tolist(),\n",
    "        \"folds\": all_results,\n",
    "        \"RMSE_mean\": float(np.mean([m[0] for m in fold_metrics])),\n",
    "        \"MAE_mean\": float(np.mean([m[1] for m in fold_metrics])),\n",
    "        \"MonotoneFrac_mean\": float(np.mean([m[2] for m in fold_metrics]))\n",
    "    }\n",
    "    with open(os.path.join(cfg.outdir, \"summary.json\"), \"w\") as f:\n",
    "        json.dump(agg, f, indent=2)\n",
    "    print(\"=== LOTO Summary ===\\n\", json.dumps(agg, indent=2))\n",
    "\n",
    "# (Optional) run:\n",
    "# run_loto_experiments(CFG, channel_cols=None)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

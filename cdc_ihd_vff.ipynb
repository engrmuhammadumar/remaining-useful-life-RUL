{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0f0ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sheet: overall final\n",
      "Detected → Year: 'Year' | AAMR: 'Age Adjusted Rate' | Group: 'Sex'\n",
      "   Year   Group  AAMR\n",
      "0  1999  Female  4.01\n",
      "1  2000  Female  3.46\n",
      "2  2001  Female  3.03\n",
      "3  2002  Female  2.68\n",
      "4  2003  Female  2.41\n",
      "5  2004  Female  2.09\n",
      "Detected groups: ['Female', 'Male', 'overall']\n",
      " [Female] order=(1, 0, 1, 'c') → CSV: D:\\arima project\\Task5\\results\\cdc_IHD_AND_VFF_finals\\overall_final\\Female_forecast_to_2043.csv\n",
      "    Plot: D:\\arima project\\Task5\\results\\cdc_IHD_AND_VFF_finals\\overall_final\\Female_timeseries_to_2043.png\n",
      " [Male] order=(2, 0, 0, 'c') → CSV: D:\\arima project\\Task5\\results\\cdc_IHD_AND_VFF_finals\\overall_final\\Male_forecast_to_2043.csv\n",
      "    Plot: D:\\arima project\\Task5\\results\\cdc_IHD_AND_VFF_finals\\overall_final\\Male_timeseries_to_2043.png\n",
      " [overall] order=(1, 0, 0, 'c') → CSV: D:\\arima project\\Task5\\results\\cdc_IHD_AND_VFF_finals\\overall_final\\overall_forecast_to_2043.csv\n",
      "    Plot: D:\\arima project\\Task5\\results\\cdc_IHD_AND_VFF_finals\\overall_final\\overall_timeseries_to_2043.png\n",
      " Consolidated CSV: D:\\arima project\\Task5\\results\\cdc_IHD_AND_VFF_finals\\overall_final\\ALL_GROUPS_forecasts_to_2043.csv\n",
      " Combined plot: D:\\arima project\\Task5\\results\\cdc_IHD_AND_VFF_finals\\overall_final\\COMBINED_timeseries_to_2043.png\n",
      "\n",
      "Done → D:\\arima project\\Task5\\results\\cdc_IHD_AND_VFF_finals\\overall_final\n"
     ]
    }
   ],
   "source": [
    "# ===== ARIMA for one sheet: \"age group final\" → CSVs + Plots to 2043 =====\n",
    "# pip install pandas numpy matplotlib statsmodels openpyxl\n",
    "import re, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "DATA_PATH   = Path(r\"D:\\arima project\\Task5\\cdc (IHD AND VFF) finals.xlsx\")   # <— your file\n",
    "SHEET_NAME = \"overall final\"                        # <— only this sheet\n",
    "RESULTS_DIR = Path(r\"D:\\arima project\\Task5\\results\")  # output root\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "END_YEAR    = 2043\n",
    "\n",
    "# If auto-detect picks the wrong metric, set this to the exact column name\n",
    "# Example: MANUAL_AAMR_COL = \"Age Adjusted Rate\"\n",
    "MANUAL_AAMR_COL = None\n",
    "\n",
    "# ---------- PLOTTING STYLE ----------\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (13.5, 8.0),\n",
    "    \"figure.dpi\": 160,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.25,\n",
    "    \"font.size\": 14,\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"axes.labelweight\": \"bold\",\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.titleweight\": \"bold\",\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"legend.frameon\": True,\n",
    "    \"legend.title_fontsize\": 13,\n",
    "    \"lines.linewidth\": 2.7,\n",
    "    \"lines.markersize\": 6.7,\n",
    "})\n",
    "\n",
    "def style_axes(ax):\n",
    "    ax.tick_params(axis=\"both\", labelsize=15, width=2.0, length=7)\n",
    "    for s in ax.spines.values():\n",
    "        s.set_linewidth(2.2)\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def _flatten_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [\n",
    "            \" \".join([str(x) for x in tup if str(x) and str(x) != \"nan\"]).strip()\n",
    "            for tup in df.columns.to_list()\n",
    "        ]\n",
    "    df.columns = [re.sub(r\"\\s+\", \" \", str(c)).strip() for c in df.columns]\n",
    "    seen = {}\n",
    "    newcols = []\n",
    "    for c in df.columns:\n",
    "        if c in seen:\n",
    "            seen[c] += 1\n",
    "            newcols.append(f\"{c}.{seen[c]}\")\n",
    "        else:\n",
    "            seen[c] = 0\n",
    "            newcols.append(c)\n",
    "    df.columns = newcols\n",
    "    return df\n",
    "\n",
    "def _pick_col(df, patterns, required=True, exclude_regex=None):\n",
    "    low = {c: str(c).strip().lower() for c in df.columns}\n",
    "    for pat in patterns:\n",
    "        rx = re.compile(pat)\n",
    "        for c, lc in low.items():\n",
    "            if rx.search(lc):\n",
    "                if exclude_regex and re.search(exclude_regex, lc):\n",
    "                    continue\n",
    "                return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Could not find any of: {patterns}\")\n",
    "    return None\n",
    "\n",
    "def find_year(df):\n",
    "    return _pick_col(df, [r\"\\byear\\b\", r\"^yr$\", r\"\\bcalendar\\s*year\\b\"])\n",
    "\n",
    "def find_aamr(df):\n",
    "    if MANUAL_AAMR_COL and MANUAL_AAMR_COL in df.columns:\n",
    "        return MANUAL_AAMR_COL\n",
    "    for p in [r\"\\bage[-\\s]*adjust(ed)?\\s*rate\\b\", r\"\\baamr\\b\", r\"\\bage[-\\s]*standard(ized)?\\s*rate\\b\"]:\n",
    "        try:\n",
    "            return _pick_col(df, [p])\n",
    "        except:\n",
    "            pass\n",
    "    # heuristic fallback\n",
    "    low = {c: str(c).strip().lower() for c in df.columns}\n",
    "    for c, lc in low.items():\n",
    "        if \"age\" in lc and \"adjust\" in lc and \"rate\" in lc and \"group\" not in lc:\n",
    "            return c\n",
    "    return _pick_col(df, [r\"\\baamr\\b\"])\n",
    "\n",
    "def find_group(df):\n",
    "    exclude = r\"age\\s*adjust|aamr|rate|ci|conf|se|stderr|mean|median|total|overall|deaths|population|percent\"\n",
    "    for pat in [r\"\\bage\\s*group(s)?\\b|age\\s*cat|age\\-group\", r\"\\bgroup\\b\", r\"\\bvariable\\b\"]:\n",
    "        c = _pick_col(df, [pat], required=False, exclude_regex=exclude)\n",
    "        if c:\n",
    "            return c\n",
    "    # If not found, but first column looks categorical, use it\n",
    "    first = df.columns[0]\n",
    "    if df[first].dtype == \"object\":\n",
    "        return first\n",
    "    return None\n",
    "\n",
    "def load_observed_excel(xls: pd.ExcelFile, sheet_name: str, overall_label=\"Overall\"):\n",
    "    df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "    df = _flatten_columns(df)\n",
    "\n",
    "    ycol = find_year(df)\n",
    "    tcol = find_aamr(df)\n",
    "    gcol = find_group(df)\n",
    "\n",
    "    # Convert numerics (also handle % strings)\n",
    "    def _to_num(s):\n",
    "        if isinstance(s, str) and s.endswith(\"%\"):\n",
    "            try:\n",
    "                return float(s.strip(\"%\")) / 100.0\n",
    "            except:\n",
    "                return np.nan\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    df[ycol] = pd.to_numeric(df[ycol], errors=\"coerce\")\n",
    "    df[tcol] = df[tcol].map(_to_num)\n",
    "\n",
    "    if gcol and gcol == tcol:\n",
    "        gcol = None\n",
    "\n",
    "    if gcol is None:\n",
    "        tidy = (df[[ycol, tcol]].dropna(subset=[ycol, tcol])\n",
    "                .groupby(ycol, as_index=False)[tcol].mean()\n",
    "                .rename(columns={ycol:\"Year\", tcol:\"AAMR\"}))\n",
    "        tidy[\"Group\"] = overall_label\n",
    "        tidy = tidy[[\"Year\",\"Group\",\"AAMR\"]]\n",
    "    else:\n",
    "        df[gcol] = df[gcol].astype(str).str.strip()\n",
    "        tidy = (df[[ycol, gcol, tcol]].dropna(subset=[ycol, gcol, tcol])\n",
    "                .groupby([ycol, gcol], as_index=False)[tcol].mean()\n",
    "                .rename(columns={ycol:\"Year\", gcol:\"Group\", tcol:\"AAMR\"}))\n",
    "\n",
    "    tidy[\"Year\"] = tidy[\"Year\"].astype(int)\n",
    "    tidy = tidy.sort_values([\"Group\",\"Year\"]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"\\nSheet: {sheet_name}\")\n",
    "    print(f\"Detected → Year: '{ycol}' | AAMR: '{tcol}' | Group: '{(gcol or overall_label)}'\")\n",
    "    print(tidy.head(6))\n",
    "    return tidy\n",
    "\n",
    "def _sanitize_series_for_arima(y: pd.Series):\n",
    "    y = y.sort_index()\n",
    "    full = pd.Index(range(int(y.index.min()), int(y.index.max())+1), name=y.index.name)\n",
    "    y = y.reindex(full)\n",
    "    if y.isna().any():\n",
    "        y = y.interpolate(limit_direction=\"both\")\n",
    "    return y\n",
    "\n",
    "def select_arima_order(y):\n",
    "    best = None\n",
    "    for d in [0,1,2]:\n",
    "        for p in range(4):\n",
    "            for q in range(4):\n",
    "                if (p,d,q) == (0,0,0):\n",
    "                    continue\n",
    "                try:\n",
    "                    trend = \"n\" if d>0 else \"c\"\n",
    "                    res = ARIMA(y, order=(p,d,q), trend=trend,\n",
    "                                enforce_stationarity=False, enforce_invertibility=False\n",
    "                               ).fit(method_kwargs={\"warn_convergence\":False})\n",
    "                    aic = res.aic\n",
    "                    if (best is None) or (aic < best[0]):\n",
    "                        best = (aic, (p,d,q,trend), res)\n",
    "                except Exception:\n",
    "                    pass\n",
    "    if best is None:\n",
    "        res = ARIMA(y, order=(1,1,0), trend=\"n\",\n",
    "                    enforce_stationarity=False, enforce_invertibility=False\n",
    "                   ).fit(method_kwargs={\"warn_convergence\":False})\n",
    "        return (1,1,0,\"n\"), res\n",
    "    return best[1], best[2]\n",
    "\n",
    "def forecast_to(y, end_year, conf=0.95):\n",
    "    last_year = int(y.index.max())\n",
    "    steps = max(0, end_year - last_year)\n",
    "    if steps == 0:\n",
    "        raise ValueError(\"Observed already reaches END_YEAR.\")\n",
    "    order, res = select_arima_order(y)\n",
    "    fc  = res.get_forecast(steps=steps)\n",
    "    ci  = fc.conf_int(alpha=1-conf)\n",
    "    yrs = list(range(last_year+1, end_year+1))\n",
    "    return order, pd.DataFrame({\n",
    "        \"Year\": yrs,\n",
    "        \"Point.Forecast\": fc.predicted_mean.values,\n",
    "        \"Lo.95\": ci.iloc[:,0].values,\n",
    "        \"Hi.95\": ci.iloc[:,1].values,\n",
    "        \"Order\": [f\"{order[0]},{order[1]},{order[2]} ({order[3]})\"]*steps\n",
    "    })\n",
    "\n",
    "def safe_name(s: str) -> str:\n",
    "    return re.sub(r\"[^a-zA-Z0-9_-]+\", \"_\", str(s)).strip(\"_\")\n",
    "\n",
    "# ---------- RUN (one sheet) ----------\n",
    "xls = pd.ExcelFile(DATA_PATH)\n",
    "assert SHEET_NAME in xls.sheet_names, f\"Sheet '{SHEET_NAME}' not found. Available: {xls.sheet_names}\"\n",
    "\n",
    "observed = load_observed_excel(xls, sheet_name=SHEET_NAME, overall_label=\"Overall\")\n",
    "groups   = sorted(observed[\"Group\"].unique())\n",
    "print(\"Detected groups:\", groups)\n",
    "\n",
    "out_root = RESULTS_DIR / safe_name(DATA_PATH.stem) / safe_name(SHEET_NAME)\n",
    "out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "all_rows = []\n",
    "last_obs_year = int(observed[\"Year\"].max())\n",
    "\n",
    "for g in groups:\n",
    "    sub = observed[observed[\"Group\"]==g].copy().dropna(subset=[\"Year\",\"AAMR\"]).sort_values(\"Year\")\n",
    "    if sub.empty:\n",
    "        print(f\" - [{g}] no data, skipping.\")\n",
    "        continue\n",
    "\n",
    "    y   = pd.Series(sub[\"AAMR\"].values, index=sub[\"Year\"].astype(int), name=\"AAMR\")\n",
    "    y   = _sanitize_series_for_arima(y)\n",
    "\n",
    "    try:\n",
    "        order, fc = forecast_to(y, end_year=END_YEAR, conf=0.95)\n",
    "    except Exception as e:\n",
    "        print(f\" - [{g}] forecast failed: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Per-group CSV\n",
    "    csv_path = out_root / f\"{safe_name(g)}_forecast_to_{END_YEAR}.csv\"\n",
    "    out = fc.copy()\n",
    "    for c in [\"Point.Forecast\",\"Lo.95\",\"Hi.95\"]:\n",
    "        out[c] = out[c].round(2)\n",
    "    out.insert(0, \"Series\", g)\n",
    "    out.to_csv(csv_path, index=False)\n",
    "    print(f\" [{g}] order={order} → CSV: {csv_path}\")\n",
    "\n",
    "    # Keep for combined CSV\n",
    "    tmp = out.copy(); tmp[\"Group\"] = g\n",
    "    all_rows.append(tmp)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(y.index, y.values, marker=\"o\", label=f\"{g} (obs)\")\n",
    "    ln, = ax.plot(fc[\"Year\"], fc[\"Point.Forecast\"], linestyle=\"--\", marker=\"o\", label=f\"{g} (fc)\")\n",
    "    lo = np.maximum(fc[\"Lo.95\"].values, 0.0)\n",
    "    ax.fill_between(fc[\"Year\"], lo, fc[\"Hi.95\"].values, alpha=0.15, color=ln.get_color(), label=\"95% CI (fc)\")\n",
    "    ax.axvline(x=last_obs_year+0.5, linestyle=\":\", linewidth=2.2)\n",
    "\n",
    "    ax.set_title(f\"{SHEET_NAME} — {g}: obs (≤{last_obs_year}) & ARIMA ({last_obs_year+1}–{END_YEAR})\")\n",
    "    ax.set_xlabel(\"Year\"); ax.set_ylabel(\"AAMR (per 100,000)\")\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n",
    "    style_axes(ax)\n",
    "    ax.legend(ncols=2)\n",
    "    plt.tight_layout()\n",
    "    png_path = out_root / f\"{safe_name(g)}_timeseries_to_{END_YEAR}.png\"\n",
    "    plt.savefig(png_path, dpi=300, bbox_inches=\"tight\"); plt.close()\n",
    "    print(f\"    Plot: {png_path}\")\n",
    "\n",
    "# Combined outputs\n",
    "if all_rows:\n",
    "    all_df = pd.concat(all_rows, ignore_index=True)\n",
    "    all_df.to_csv(out_root / f\"ALL_GROUPS_forecasts_to_{END_YEAR}.csv\", index=False)\n",
    "    print(\" Consolidated CSV:\", out_root / f\"ALL_GROUPS_forecasts_to_{END_YEAR}.csv\")\n",
    "\n",
    "    # Combined plot\n",
    "    fig, ax = plt.subplots()\n",
    "    added_ci = False\n",
    "    for g in groups:\n",
    "        sub = observed[observed[\"Group\"]==g].copy().sort_values(\"Year\")\n",
    "        if sub.empty: \n",
    "            continue\n",
    "        ax.plot(sub[\"Year\"], sub[\"AAMR\"], marker=\"o\", label=f\"{g} (obs)\")\n",
    "        fc_path = out_root / f\"{safe_name(g)}_forecast_to_{END_YEAR}.csv\"\n",
    "        if fc_path.exists():\n",
    "            fc = pd.read_csv(fc_path)\n",
    "            ln, = ax.plot(fc[\"Year\"], fc[\"Point.Forecast\"], linestyle=\"--\", marker=\"o\", label=f\"{g} (fc)\")\n",
    "            lo = np.maximum(fc[\"Lo.95\"].values, 0.0)\n",
    "            if not added_ci:\n",
    "                ax.fill_between(fc[\"Year\"], lo, fc[\"Hi.95\"].values, alpha=0.12, color=ln.get_color(), label=\"95% CI (fc)\")\n",
    "                added_ci = True\n",
    "            else:\n",
    "                ax.fill_between(fc[\"Year\"], lo, fc[\"Hi.95\"].values, alpha=0.12, color=ln.get_color())\n",
    "\n",
    "    ax.axvline(x=last_obs_year+0.5, linestyle=\":\", linewidth=2.2)\n",
    "    ax.set_title(f\"{SHEET_NAME} (≤{last_obs_year}) ARIMA ({last_obs_year+1}–{END_YEAR})\")\n",
    "    ax.set_xlabel(\"Year\"); ax.set_ylabel(\"AAMR (per 100,000)\")\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n",
    "    style_axes(ax)\n",
    "    ax.legend(ncols=2)\n",
    "    ax.margins(x=0.02)\n",
    "    plt.tight_layout()\n",
    "    combined_png = out_root / f\"COMBINED_timeseries_to_{END_YEAR}.png\"\n",
    "    plt.savefig(combined_png, dpi=300, bbox_inches=\"tight\"); plt.close()\n",
    "    print(\" Combined plot:\", combined_png)\n",
    "\n",
    "print(\"\\nDone →\", out_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51667123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\arima project\\Task5\\results\\cdc_IHD_AND_VFF_finals\\overall_final\\TOTAL_forecasts_to_2043.csv\n",
      "   Year  Point.Forecast  Lo.95  Hi.95\n",
      "0  2024            6.08   5.76   6.40\n",
      "1  2025            6.10   5.70   6.48\n",
      "2  2026            6.10   5.67   6.54\n",
      "3  2027            6.12   5.66   6.57\n",
      "4  2028            6.13   5.65   6.59\n",
      "5  2029            6.13   5.65   6.62\n",
      "6  2030            6.13   5.64   6.61\n",
      "7  2031            6.13   5.64   6.62\n",
      "8  2032            6.14   5.65   6.64\n",
      "9  2033            6.14   5.65   6.64\n"
     ]
    }
   ],
   "source": [
    "# ===== Post-process totals across groups =====\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Point this to your results folder where ALL_GROUPS_forecasts_to_2043.csv is saved\n",
    "all_groups_path = Path(r\"D:\\arima project\\Task5\\results\\cdc_IHD_AND_VFF_finals\\overall_final\\ALL_GROUPS_forecasts_to_2043.csv\")\n",
    "\n",
    "# Load combined forecasts\n",
    "df = pd.read_csv(all_groups_path)\n",
    "\n",
    "# Calculate totals across groups per year\n",
    "totals = (\n",
    "    df.groupby(\"Year\")\n",
    "      .agg({\n",
    "          \"Point.Forecast\": \"sum\",\n",
    "          \"Lo.95\": \"sum\",\n",
    "          \"Hi.95\": \"sum\"\n",
    "      })\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Save totals\n",
    "out_path = all_groups_path.parent / \"TOTAL_forecasts_to_2043.csv\"\n",
    "totals.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)\n",
    "print(totals.head(10))   # peek at first 10 years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab50cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sheet: overall final\n",
      "  Saved: D:\\arima project\\Task5\\observed_totals_1999_2023\\overall_final_TOTALS_1999_2023.csv\n",
      "\n",
      "Processing sheet: age group final\n",
      "  Saved: D:\\arima project\\Task5\\observed_totals_1999_2023\\age_group_final_TOTALS_1999_2023.csv\n",
      "⚠️ Sheet not found: Race final. Available: ['overall final', 'Race final ', 'census final', 'state final', 'urbanization final', 'age group final']\n",
      "\n",
      "Processing sheet: census final\n",
      "  Saved: D:\\arima project\\Task5\\observed_totals_1999_2023\\census_final_TOTALS_1999_2023.csv\n",
      "\n",
      "Processing sheet: urbanization final\n",
      "  Saved: D:\\arima project\\Task5\\observed_totals_1999_2023\\urbanization_final_TOTALS_1999_2023.csv\n",
      "\n",
      "✅ Master totals saved: D:\\arima project\\Task5\\observed_totals_1999_2023\\MASTER_TOTALS_1999_2023.csv\n"
     ]
    }
   ],
   "source": [
    "# ===== Totals of observed AAMRs (1999–2023) by variable =====\n",
    "# pip install pandas openpyxl\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- CONFIG ----\n",
    "DATA_PATH   = Path(r\"D:\\arima project\\Task5\\cdc (IHD AND VFF) finals.xlsx\")  # your workbook\n",
    "SHEET_NAMES = [\"overall final\", \"age group final\", \"Race final \", \"census final\", \"urbanization final\"]\n",
    "OUT_DIR     = Path(r\"D:\\arima project\\Task5\\observed_totals_1999_2023\")      # where to save\n",
    "YEAR_MIN, YEAR_MAX = 1999, 2023\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- HELPERS ----\n",
    "def _flatten_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [\n",
    "            \" \".join([str(x) for x in tup if str(x) and str(x) != \"nan\"]).strip()\n",
    "            for tup in df.columns.to_list()\n",
    "        ]\n",
    "    df.columns = [re.sub(r\"\\s+\", \" \", str(c)).strip() for c in df.columns]\n",
    "    # disambiguate duplicates\n",
    "    seen = {}\n",
    "    newcols = []\n",
    "    for c in df.columns:\n",
    "        if c in seen:\n",
    "            seen[c] += 1\n",
    "            newcols.append(f\"{c}.{seen[c]}\")\n",
    "        else:\n",
    "            seen[c] = 0\n",
    "            newcols.append(c)\n",
    "    df.columns = newcols\n",
    "    return df\n",
    "\n",
    "def _pick_col(df, patterns, required=True, exclude_regex=None):\n",
    "    low = {c: str(c).lower().strip() for c in df.columns}\n",
    "    for pat in patterns:\n",
    "        rx = re.compile(pat)\n",
    "        for c, lc in low.items():\n",
    "            if rx.search(lc):\n",
    "                if exclude_regex and re.search(exclude_regex, lc):\n",
    "                    continue\n",
    "                return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Could not find any of: {patterns}\")\n",
    "    return None\n",
    "\n",
    "def find_year(df):     return _pick_col(df, [r\"\\byear\\b\", r\"^yr$\", r\"calendar\\s*year\"])\n",
    "def find_group(df):\n",
    "    exclude = r\"age\\s*adjust|aamr|rate|ci|conf|se|stderr|mean|median|total|overall|deaths|population|percent\"\n",
    "    for pat in [r\"\\bage\\s*group(s)?\\b|age\\s*cat|age\\-group\", r\"\\bgroup\\b\", r\"\\bvariable\\b\"]:\n",
    "        c = _pick_col(df, [pat], required=False, exclude_regex=exclude)\n",
    "        if c: return c\n",
    "    # fallback: if first column looks categorical, use it\n",
    "    first = df.columns[0]\n",
    "    return first if df[first].dtype == \"object\" else None\n",
    "\n",
    "def find_aamr(df):\n",
    "    for p in [r\"\\bage[-\\s]*adjust(ed)?\\s*rate\\b\", r\"\\baamr\\b\", r\"age[-\\s]*standard(ized)?\\s*rate\"]:\n",
    "        try: return _pick_col(df, [p])\n",
    "        except: pass\n",
    "    # heuristic\n",
    "    low = {c: str(c).lower() for c in df.columns}\n",
    "    for c, lc in low.items():\n",
    "        if \"age\" in lc and \"adjust\" in lc and \"rate\" in lc and \"group\" not in lc:\n",
    "            return c\n",
    "    return _pick_col(df, [r\"\\baamr\\b\"])\n",
    "\n",
    "def find_ci_low(df):\n",
    "    return _pick_col(df, [r\"\\blo(\\.?\\s*95)?\\b\", r\"\\blower\\b\", r\"\\bci\\s*low\\b\", r\"\\blcl\\b\"], required=False)\n",
    "\n",
    "def find_ci_high(df):\n",
    "    return _pick_col(df, [r\"\\bhi(\\.?\\s*95)?\\b\", r\"\\bupper\\b\", r\"\\bci\\s*high\\b\", r\"\\bucl\\b\"], required=False)\n",
    "\n",
    "def _to_num(x):\n",
    "    if isinstance(x, str) and x.endswith(\"%\"):\n",
    "        try: return float(x.strip(\"%\")) / 100.0\n",
    "        except: return np.nan\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "def load_observed_tidy(xls: pd.ExcelFile, sheet: str):\n",
    "    df = pd.read_excel(xls, sheet_name=sheet)\n",
    "    df = _flatten_columns(df)\n",
    "\n",
    "    ycol  = find_year(df)\n",
    "    gcol  = find_group(df)\n",
    "    rcol  = find_aamr(df)\n",
    "    loCol = find_ci_low(df)\n",
    "    hiCol = find_ci_high(df)\n",
    "\n",
    "    # coerce numerics\n",
    "    df[ycol] = pd.to_numeric(df[ycol], errors=\"coerce\")\n",
    "    df[rcol] = df[rcol].map(_to_num)\n",
    "    if loCol: df[loCol] = df[loCol].map(_to_num)\n",
    "    if hiCol: df[hiCol] = df[hiCol].map(_to_num)\n",
    "\n",
    "    # keep needed cols\n",
    "    cols = [c for c in [ycol, gcol, rcol, loCol, hiCol] if c is not None]\n",
    "    df = df[cols].dropna(subset=[ycol, rcol])\n",
    "\n",
    "    # standardize names\n",
    "    rename_map = {ycol: \"Year\", rcol: \"AAMR\"}\n",
    "    if gcol:  rename_map[gcol] = \"Group\"\n",
    "    if loCol: rename_map[loCol] = \"Lo.95\"\n",
    "    if hiCol: rename_map[hiCol] = \"Hi.95\"\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    # aggregate if duplicates\n",
    "    by = [\"Year\"] + ([\"Group\"] if \"Group\" in df.columns else [])\n",
    "    agg_map = {\"AAMR\":\"mean\"}\n",
    "    if \"Lo.95\" in df.columns: agg_map[\"Lo.95\"] = \"mean\"\n",
    "    if \"Hi.95\" in df.columns: agg_map[\"Hi.95\"] = \"mean\"\n",
    "    df = df.groupby(by, as_index=False).agg(agg_map)\n",
    "\n",
    "    # filter observed window\n",
    "    df = df[(df[\"Year\"] >= YEAR_MIN) & (df[\"Year\"] <= YEAR_MAX)].copy()\n",
    "    df = df.sort_values(by).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def compute_totals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Sum across groups per year (AAMR, Lo.95, Hi.95). If CI columns\n",
    "    are missing, return NaN for them.\"\"\"\n",
    "    if \"Group\" not in df.columns:\n",
    "        # single series (no groups) -> 'Total' is just the series itself\n",
    "        out = df[[\"Year\", \"AAMR\"]].copy()\n",
    "        out[\"Lo.95\"] = df.get(\"Lo.95\", np.nan)\n",
    "        out[\"Hi.95\"] = df.get(\"Hi.95\", np.nan)\n",
    "        out = out.rename(columns={\"AAMR\":\"Total.Point\", \"Lo.95\":\"Total.Lo.95\", \"Hi.95\":\"Total.Hi.95\"})\n",
    "        return out\n",
    "\n",
    "    agg_cols = {\"AAMR\": \"sum\"}\n",
    "    if \"Lo.95\" in df.columns: agg_cols[\"Lo.95\"] = \"sum\"\n",
    "    if \"Hi.95\" in df.columns: agg_cols[\"Hi.95\"] = \"sum\"\n",
    "\n",
    "    out = (df.groupby(\"Year\", as_index=False)\n",
    "             .agg(agg_cols)\n",
    "             .rename(columns={\"AAMR\":\"Total.Point\",\n",
    "                              \"Lo.95\":\"Total.Lo.95\",\n",
    "                              \"Hi.95\":\"Total.Hi.95\"}))\n",
    "    return out\n",
    "\n",
    "# ---- RUN ----\n",
    "xls = pd.ExcelFile(DATA_PATH)\n",
    "master_rows = []\n",
    "\n",
    "for sheet in SHEET_NAMES:\n",
    "    if sheet not in xls.sheet_names:\n",
    "        print(f\"⚠️ Sheet not found: {sheet}. Available: {xls.sheet_names}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing sheet: {sheet}\")\n",
    "    tidy = load_observed_tidy(xls, sheet)\n",
    "\n",
    "    totals = compute_totals(tidy)\n",
    "    totals[\"Variable\"] = sheet\n",
    "\n",
    "    # Save per-sheet totals\n",
    "    out_file = OUT_DIR / f\"{sheet.replace(' ', '_')}_TOTALS_1999_2023.csv\"\n",
    "    totals.to_csv(out_file, index=False)\n",
    "    print(\"  Saved:\", out_file)\n",
    "\n",
    "    master_rows.append(totals)\n",
    "\n",
    "# Save a master file with all variables appended\n",
    "if master_rows:\n",
    "    master = pd.concat(master_rows, ignore_index=True)\n",
    "    master = master[[\"Variable\", \"Year\", \"Total.Point\", \"Total.Lo.95\", \"Total.Hi.95\"]]\n",
    "    master_file = OUT_DIR / \"MASTER_TOTALS_1999_2023.csv\"\n",
    "    master.to_csv(master_file, index=False)\n",
    "    print(\"\\n✅ Master totals saved:\", master_file)\n",
    "else:\n",
    "    print(\"\\nNo outputs created. Check sheet names and column detection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eca6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b02eb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed:\n",
    "# !pip install pandas numpy matplotlib openpyxl statsmodels\n",
    "\n",
    "import re, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------- YOUR FILE & OUTPUT ROOT ----------\n",
    "FILE_PATH = r\"D:\\arima project\\Task3\\Task 3\\cdc (IHD AND VFF) finals.xlsx\"\n",
    "BASE_RESULTS_DIR = Path(r\"D:\\arima project\\Task3\\Task 3\\results\")\n",
    "BASE_RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Forecast horizon\n",
    "END_YEAR = 2043\n",
    "\n",
    "# Optional: if a sheet needs a specific AAMR column, put it here (by sheet name, exact)\n",
    "MANUAL_AAMR_BY_SHEET = {\n",
    "    # \"overall final\": \"Age Adjusted Rate\",   # example if auto-pick ever fails\n",
    "}\n",
    "\n",
    "# For very crowded sheets (e.g., states), show only top N groups in the combined plot (None = all)\n",
    "TOP_N_IN_COMBINED = {\n",
    "    \"state final\": 12,   # keep combined figure readable\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f0f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (14, 8),\n",
    "    \"figure.dpi\": 160,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.25,\n",
    "    \"font.size\": 16,\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"axes.labelweight\": \"bold\",\n",
    "    \"axes.titlesize\": 24,\n",
    "    \"axes.titleweight\": \"bold\",\n",
    "    \"legend.fontsize\": 14,\n",
    "    \"legend.frameon\": True,\n",
    "    \"legend.title_fontsize\": 15,\n",
    "    \"lines.linewidth\": 2.8,\n",
    "    \"lines.markersize\": 7.0,\n",
    "})\n",
    "\n",
    "def style_axes(ax):\n",
    "    ax.tick_params(axis=\"both\", labelsize=16, width=2.2, length=7)\n",
    "    for s in ax.spines.values():\n",
    "        s.set_linewidth(2.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "964db181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_name(s: str) -> str:\n",
    "    return re.sub(r\"[^a-zA-Z0-9_-]+\", \"_\", str(s)).strip(\"_\")\n",
    "\n",
    "def _flatten_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Flatten multirow headers, normalize whitespace, deduplicate names.\"\"\"\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [\n",
    "            \" \".join([str(x) for x in tup if (str(x) != \"nan\" and str(x).strip() != \"\")]).strip()\n",
    "            for tup in df.columns.to_list()\n",
    "        ]\n",
    "    df.columns = [re.sub(r\"\\s+\", \" \", str(c)).strip() for c in df.columns]\n",
    "    seen, newcols = {}, []\n",
    "    for c in df.columns:\n",
    "        if c in seen:\n",
    "            seen[c] += 1\n",
    "            newcols.append(f\"{c}.{seen[c]}\")\n",
    "        else:\n",
    "            seen[c] = 0\n",
    "            newcols.append(c)\n",
    "    df.columns = newcols\n",
    "    return df\n",
    "\n",
    "def _pick_col(df, patterns, required=True, exclude_regex=None):\n",
    "    low = {c: str(c).strip().lower() for c in df.columns}\n",
    "    for pat in patterns:\n",
    "        rx = re.compile(pat)\n",
    "        for c, lc in low.items():\n",
    "            if rx.search(lc):\n",
    "                if exclude_regex and re.search(exclude_regex, lc):\n",
    "                    continue\n",
    "                return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Could not find any of: {patterns}\")\n",
    "    return None\n",
    "\n",
    "def find_year(df):  # prefer 'Year'\n",
    "    return _pick_col(df, [r\"\\byear\\b\", r\"^yr$\", r\"\\bcalendar\\s*year\\b\"])\n",
    "\n",
    "def find_group(df):\n",
    "    \"\"\"Likely grouping column (Sex/Age group/Race/Region/Urbanization/State/Variable).\"\"\"\n",
    "    exclude = r\"age\\s*adjust|aamr|rate|ci|confidence|se|std|mean|median|total\\s*deaths|deaths\"\n",
    "    patterns = [\n",
    "        r\"\\bvariable\\b\",\n",
    "        r\"\\bage\\s*group(s)?\\b|age\\s*cat(egory|egories)?\\b|age\\s*grp\\b|age\\-group\",\n",
    "        r\"\\bgender\\b|\\bsex\\b\",\n",
    "        r\"\\brace\\b|ethnic|hispanic\",\n",
    "        r\"\\bregion\\b|census\",\n",
    "        r\"\\burban(ization)?\\b|rural\\b\",\n",
    "        r\"\\bstate\\b|^us state$|^state name$\",\n",
    "        r\"\\boverall\\b|^total$\"\n",
    "    ]\n",
    "    for pat in patterns:\n",
    "        c = _pick_col(df, [pat], required=False, exclude_regex=exclude)\n",
    "        if c:\n",
    "            return c\n",
    "    return None  # overall-only sheet\n",
    "\n",
    "def find_aamr(df, sheet_name=None):\n",
    "    # Manual override per sheet (if provided)\n",
    "    if sheet_name and sheet_name in MANUAL_AAMR_BY_SHEET:\n",
    "        col = MANUAL_AAMR_BY_SHEET[sheet_name]\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "\n",
    "    # 1) Precise names\n",
    "    precise = [\n",
    "        r\"\\bage[-\\s]*adjust(ed)?\\s*rate\\b\",\n",
    "        r\"\\baamr\\b\",\n",
    "        r\"\\bage[-\\s]*standard(ized)?\\s*rate\\b\"\n",
    "    ]\n",
    "    for p in precise:\n",
    "        try:\n",
    "            return _pick_col(df, [p])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # 2) Generic 'Age Adjust*' that LOOKS like a rate (numeric, not %)\n",
    "    bad_words = (\"death\", \"%\", \"percent\", \"share\")\n",
    "    candidates = []\n",
    "    for c in df.columns:\n",
    "        lc = str(c).lower()\n",
    "        if \"age\" in lc and \"adjust\" in lc and not any(b in lc for b in bad_words):\n",
    "            # Prefer columns that are mostly numeric\n",
    "            vals = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "            nn = vals.notna().sum()\n",
    "            if nn >= max(5, int(0.5 * len(df))):  # many numeric entries\n",
    "                candidates.append((nn, c))\n",
    "    if candidates:\n",
    "        # pick the one with the MOST numeric values (usually the main rate)\n",
    "        candidates.sort(reverse=True)\n",
    "        return candidates[0][1]\n",
    "\n",
    "    # 3) Last resort: any numeric column with 'rate' in name\n",
    "    for c in df.columns:\n",
    "        lc = str(c).lower()\n",
    "        if \"rate\" in lc:\n",
    "            vals = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "            if vals.notna().sum() >= 5:\n",
    "                return c\n",
    "\n",
    "    raise KeyError(\"AAMR column not found. Set MANUAL_AAMR_BY_SHEET for this sheet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6afe5c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_observed_excel(path, sheet_name, overall_label=\"Overall\"):\n",
    "    xls = pd.ExcelFile(path)\n",
    "    if sheet_name not in xls.sheet_names:\n",
    "        raise ValueError(f\"Sheet '{sheet_name}' not found. Options: {xls.sheet_names}\")\n",
    "\n",
    "    df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "    df = _flatten_columns(df)\n",
    "\n",
    "    ycol = find_year(df)\n",
    "    tcol = find_aamr(df, sheet_name=sheet_name)\n",
    "    gcol = find_group(df)  # may be None\n",
    "\n",
    "    df[ycol] = pd.to_numeric(df[ycol], errors=\"coerce\")\n",
    "    df[tcol] = pd.to_numeric(df[tcol], errors=\"coerce\")\n",
    "\n",
    "    if gcol and gcol == tcol:\n",
    "        gcol = None\n",
    "\n",
    "    if gcol is None:\n",
    "        tidy = (df[[ycol, tcol]]\n",
    "                .dropna(subset=[ycol, tcol])\n",
    "                .groupby(ycol, as_index=False)[tcol].mean()\n",
    "                .rename(columns={ycol:\"Year\", tcol:\"AAMR\"}))\n",
    "        tidy[\"Group\"] = overall_label\n",
    "        tidy = tidy[[\"Year\",\"Group\",\"AAMR\"]]\n",
    "    else:\n",
    "        df[gcol] = df[gcol].astype(str).str.strip()\n",
    "        tidy = (df[[ycol, gcol, tcol]]\n",
    "                .dropna(subset=[ycol, gcol, tcol])\n",
    "                .groupby([ycol, gcol], as_index=False)[tcol].mean()\n",
    "                .rename(columns={ycol:\"Year\", gcol:\"Group\", tcol:\"AAMR\"}))\n",
    "\n",
    "    tidy[\"Year\"] = tidy[\"Year\"].astype(int)\n",
    "    tidy = tidy.sort_values([\"Group\",\"Year\"]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"\\nSheet: {sheet_name}\")\n",
    "    print(f\"Detected â†’ Year: '{ycol}' | AAMR: '{tcol}' | Group: '{(gcol or overall_label)}'\")\n",
    "    print(tidy.head(6))\n",
    "    return tidy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a15d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sanitize_series_for_arima(y: pd.Series):\n",
    "    y = y.sort_index()\n",
    "    full = pd.Index(range(int(y.index.min()), int(y.index.max())+1), name=y.index.name)\n",
    "    y = y.reindex(full)\n",
    "    if y.isna().any():\n",
    "        y = y.interpolate(limit_direction=\"both\")\n",
    "    return y\n",
    "\n",
    "def select_arima_order(y):\n",
    "    best = None\n",
    "    for d in [0,1,2]:\n",
    "        for p in range(0,4):\n",
    "            for q in range(0,4):\n",
    "                if (p,d,q) == (0,0,0):\n",
    "                    continue\n",
    "                try:\n",
    "                    trend = \"n\" if d>0 else \"c\"\n",
    "                    res = ARIMA(y, order=(p,d,q), trend=trend,\n",
    "                                enforce_stationarity=False, enforce_invertibility=False\n",
    "                               ).fit(method_kwargs={\"warn_convergence\":False})\n",
    "                    score = res.aic\n",
    "                    if (best is None) or (score < best[0]):\n",
    "                        best = (score, (p,d,q,trend), res)\n",
    "                except Exception:\n",
    "                    pass\n",
    "    if best is None:\n",
    "        res = ARIMA(y, order=(1,1,0), trend=\"n\",\n",
    "                    enforce_stationarity=False, enforce_invertibility=False\n",
    "                   ).fit(method_kwargs={\"warn_convergence\":False})\n",
    "        return (1,1,0,\"n\"), res\n",
    "    return best[1], best[2]\n",
    "\n",
    "def forecast_to(y, end_year, conf=0.95):\n",
    "    last_year = int(y.index.max())\n",
    "    steps = max(0, end_year - last_year)\n",
    "    if steps == 0:\n",
    "        raise ValueError(\"Observed series already extends to END_YEAR.\")\n",
    "    order, res = select_arima_order(y)\n",
    "    fc = res.get_forecast(steps=steps)\n",
    "    mean = fc.predicted_mean\n",
    "    ci   = fc.conf_int(alpha=1-conf)\n",
    "    lo, hi = ci.iloc[:,0], ci.iloc[:,1]\n",
    "    yrs = list(range(last_year+1, end_year+1))\n",
    "    out = pd.DataFrame({\n",
    "        \"Year\": yrs,\n",
    "        \"Point.Forecast\": mean.values,\n",
    "        \"Lo.95\": lo.values,\n",
    "        \"Hi.95\": hi.values,\n",
    "        \"Order\": [f\"{order[0]},{order[1]},{order[2]} ({order[3]})\"]*steps\n",
    "    })\n",
    "    return order, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "312d5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_all_groups_and_save(observed_df, end_year, out_dir: Path, title_prefix=\"AAMR\"):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    groups = sorted(observed_df[\"Group\"].unique())\n",
    "    all_rows = []\n",
    "    last_obs_year = int(observed_df[\"Year\"].max())\n",
    "\n",
    "    for g in groups:\n",
    "        sub = observed_df[observed_df[\"Group\"]==g].copy()\n",
    "        sub = sub.dropna(subset=[\"Year\",\"AAMR\"]).sort_values(\"Year\")\n",
    "        y = pd.Series(sub[\"AAMR\"].values, index=sub[\"Year\"].astype(int), name=\"AAMR\")\n",
    "        y = _sanitize_series_for_arima(y)\n",
    "\n",
    "        order, fc = forecast_to(y, end_year=end_year, conf=0.95)\n",
    "\n",
    "        # Save per-group CSV (2 decimals)\n",
    "        csv_path = out_dir / f\"{safe_name(g)}_forecast_to_{end_year}.csv\"\n",
    "        fc_out = fc.copy()\n",
    "        for c in [\"Point.Forecast\",\"Lo.95\",\"Hi.95\"]:\n",
    "            fc_out[c] = fc_out[c].round(2)\n",
    "        fc_out.insert(0, \"Series\", g)\n",
    "        fc_out.to_csv(csv_path, index=False)\n",
    "        print(f\"[{g}] order={order}  -> CSV:\", csv_path)\n",
    "\n",
    "        # Per-group plot with CI (no annotations at the end)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(y.index, y.values, marker=\"o\", label=f\"{g} (obs)\")\n",
    "        ln, = ax.plot(fc[\"Year\"], fc[\"Point.Forecast\"], linestyle=\"--\", marker=\"o\", label=f\"{g} (fc)\")\n",
    "        ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.14, color=ln.get_color(), label=\"95% PI (fc)\")\n",
    "        ax.axvline(x=last_obs_year+0.5, linestyle=\":\", linewidth=2.2)\n",
    "        ax.set_title(f\"{title_prefix}: {g} â€” observed (â‰¤{last_obs_year}) & ARIMA forecast ({last_obs_year+1}â€“{end_year})\")\n",
    "        ax.set_xlabel(\"Year\"); ax.set_ylabel(\"AAMR (per 100,000)\")\n",
    "        ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n",
    "        style_axes(ax)\n",
    "        ax.legend(ncols=2)\n",
    "        plt.tight_layout()\n",
    "        png_path = out_dir / f\"{safe_name(g)}_timeseries_to_{end_year}.png\"\n",
    "        plt.savefig(png_path, dpi=300, bbox_inches=\"tight\"); plt.close()\n",
    "        print(\"   Plot:\", png_path)\n",
    "\n",
    "        # keep for consolidated\n",
    "        tmp = fc_out.copy(); tmp[\"Group\"] = g\n",
    "        all_rows.append(tmp)\n",
    "\n",
    "    if all_rows:\n",
    "        all_df = pd.concat(all_rows, ignore_index=True)\n",
    "        all_df.to_csv(out_dir / f\"ALL_GROUPS_forecasts_to_{end_year}.csv\", index=False)\n",
    "        print(\"Consolidated CSV:\", out_dir / f\"ALL_GROUPS_forecasts_to_{end_year}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e76b176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined(observed_df, out_dir: Path, end_year: int, title=\"AAMR\", top_n=None):\n",
    "    last_obs_year = int(observed_df[\"Year\"].max())\n",
    "    groups = sorted(observed_df[\"Group\"].unique())\n",
    "\n",
    "    # Optionally restrict to top N by last observed AAMR\n",
    "    if top_n is not None and len(groups) > top_n:\n",
    "        last_vals = (observed_df.sort_values(\"Year\")\n",
    "                     .groupby(\"Group\")[\"AAMR\"].last().sort_values(ascending=False))\n",
    "        keep = set(last_vals.head(top_n).index.tolist())\n",
    "        observed_df = observed_df[observed_df[\"Group\"].isin(keep)]\n",
    "        groups = sorted(keep)\n",
    "\n",
    "    # Read saved forecasts for CI\n",
    "    fc_map = {}\n",
    "    for g in groups:\n",
    "        p = out_dir / f\"{safe_name(g)}_forecast_to_{end_year}.csv\"\n",
    "        if p.exists():\n",
    "            fc_map[g] = pd.read_csv(p)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ci_legend_added = False\n",
    "\n",
    "    for g in groups:\n",
    "        sub = observed_df[observed_df[\"Group\"]==g].copy().sort_values(\"Year\")\n",
    "        ax.plot(sub[\"Year\"], sub[\"AAMR\"], marker=\"o\", label=f\"{g} (obs)\")\n",
    "        if g in fc_map:\n",
    "            fc = fc_map[g]\n",
    "            ln, = ax.plot(fc[\"Year\"], fc[\"Point.Forecast\"], linestyle=\"--\", marker=\"o\", label=f\"{g} (fc)\")\n",
    "            if not ci_legend_added:\n",
    "                ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.12, color=ln.get_color(), label=\"95% PI (fc)\")\n",
    "                ci_legend_added = True\n",
    "            else:\n",
    "                ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.12, color=ln.get_color())\n",
    "\n",
    "    ax.axvline(x=last_obs_year+0.5, linestyle=\":\", linewidth=2.2)\n",
    "    ax.set_title(f\"{title}: observed (â‰¤{last_obs_year}) & ARIMA forecast ({last_obs_year+1}â€“{end_year})\")\n",
    "    ax.set_xlabel(\"Year\"); ax.set_ylabel(\"AAMR (per 100,000)\")\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n",
    "    style_axes(ax)\n",
    "    ax.legend(ncols=2)\n",
    "    ax.margins(x=0.02)\n",
    "    plt.tight_layout()\n",
    "    out = out_dir / f\"COMBINED_timeseries_to_{end_year}.png\"\n",
    "    plt.savefig(out, dpi=300, bbox_inches=\"tight\"); plt.close()\n",
    "    print(\"Combined plot:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f5ea7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sheet: overall final\n",
      "Detected â†’ Year: 'Year' | AAMR: 'Age Adjusted Rate' | Group: 'Overall'\n",
      "   Year    Group      AAMR\n",
      "0  1999  Overall  6.916667\n",
      "1  2000  Overall  6.166667\n",
      "2  2001  Overall  5.406667\n",
      "3  2002  Overall  4.800000\n",
      "4  2003  Overall  4.310000\n",
      "5  2004  Overall  3.853333\n",
      "[Overall] order=(1, 0, 0, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\overall\\Overall_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\overall\\Overall_timeseries_to_2043.png\n",
      "Consolidated CSV: D:\\arima project\\Task3\\Task 3\\results\\overall\\ALL_GROUPS_forecasts_to_2043.csv\n",
      "Combined plot: D:\\arima project\\Task3\\Task 3\\results\\overall\\COMBINED_timeseries_to_2043.png\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sheet 'Race final' not found. Options: ['overall final', 'Race final ', 'census final', 'state final', 'urbanization final', 'age group final']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m out_dir\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 1) Load & tidy\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m observed \u001b[38;5;241m=\u001b[39m load_observed_excel(FILE_PATH, sheet_name\u001b[38;5;241m=\u001b[39msheet_name, overall_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 2) Fit & save per group (CSV + per-group plot)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m fit_all_groups_and_save(observed, END_YEAR, out_dir, title_prefix\u001b[38;5;241m=\u001b[39mpretty_title)\n",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36mload_observed_excel\u001b[1;34m(path, sheet_name, overall_label)\u001b[0m\n\u001b[0;32m      2\u001b[0m xls \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mExcelFile(path)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sheet_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m xls\u001b[38;5;241m.\u001b[39msheet_names:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSheet \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found. Options: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxls\u001b[38;5;241m.\u001b[39msheet_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(xls, sheet_name\u001b[38;5;241m=\u001b[39msheet_name)\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m _flatten_columns(df)\n",
      "\u001b[1;31mValueError\u001b[0m: Sheet 'Race final' not found. Options: ['overall final', 'Race final ', 'census final', 'state final', 'urbanization final', 'age group final']"
     ]
    }
   ],
   "source": [
    "# Map sheet name -> nice folder name & plot title\n",
    "RUN_SHEETS = [\n",
    "    (\"overall final\",       \"overall\",       \"Overall\"),\n",
    "    (\"Race final\",          \"race\",          \"Race/Ethnicity\"),\n",
    "    (\"census final\",        \"region\",        \"Census Region\"),\n",
    "    (\"state final\",         \"state\",         \"States\"),\n",
    "    (\"urbanization final\",  \"urbanization\",  \"Urbanization\"),\n",
    "    (\"age group final\",     \"age\",           \"Age groups\"),\n",
    "]\n",
    "\n",
    "for sheet_name, folder, pretty_title in RUN_SHEETS:\n",
    "    out_dir = BASE_RESULTS_DIR / folder\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Load & tidy\n",
    "    observed = load_observed_excel(FILE_PATH, sheet_name=sheet_name, overall_label=\"Overall\")\n",
    "\n",
    "    # 2) Fit & save per group (CSV + per-group plot)\n",
    "    fit_all_groups_and_save(observed, END_YEAR, out_dir, title_prefix=pretty_title)\n",
    "\n",
    "    # 3) Combined figure (optionally limit groups)\n",
    "    topn = TOP_N_IN_COMBINED.get(sheet_name)\n",
    "    plot_combined(observed, out_dir, END_YEAR, title=pretty_title, top_n=topn)\n",
    "\n",
    "print(\"\\nAll done. Files saved under:\", BASE_RESULTS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3681f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ac21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b5b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6384a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c59b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58058ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sheet: overall final\n",
      "Detected â†’ Year: 'Year' | AAMR: 'Age Adjusted Rate' | Group: 'Overall'\n",
      "   Year    Group      AAMR\n",
      "0  1999  Overall  6.916667\n",
      "1  2000  Overall  6.166667\n",
      "2  2001  Overall  5.406667\n",
      "3  2002  Overall  4.800000\n",
      "4  2003  Overall  4.310000\n",
      "5  2004  Overall  3.853333\n",
      "[Overall] order=(1, 0, 0, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\overall\\Overall_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\overall\\Overall_timeseries_to_2043.png\n",
      "Consolidated CSV: D:\\arima project\\Task3\\Task 3\\results\\overall\\ALL_GROUPS_forecasts_to_2043.csv\n",
      "Combined plot: D:\\arima project\\Task3\\Task 3\\results\\overall\\COMBINED_timeseries_to_2043.png\n",
      "\n",
      "Sheet: Race final \n",
      "Detected â†’ Year: 'Year' | AAMR: 'Age Adjusted Rate' | Group: 'Hispanic Origin'\n",
      "   Year                             Group  AAMR\n",
      "0  1999  American Indian or Alaska Native  4.44\n",
      "1  2000  American Indian or Alaska Native  4.81\n",
      "2  2001  American Indian or Alaska Native  3.49\n",
      "3  2002  American Indian or Alaska Native  3.76\n",
      "4  2003  American Indian or Alaska Native  3.07\n",
      "5  2004  American Indian or Alaska Native  4.23\n",
      "[American Indian or Alaska Native] order=(1, 0, 3, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\race\\American_Indian_or_Alaska_Native_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\race\\American_Indian_or_Alaska_Native_timeseries_to_2043.png\n",
      "[Asian or Pacific Islander] order=(1, 0, 3, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\race\\Asian_or_Pacific_Islander_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\race\\Asian_or_Pacific_Islander_timeseries_to_2043.png\n",
      "[Black or African American] order=(3, 0, 2, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\race\\Black_or_African_American_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\race\\Black_or_African_American_timeseries_to_2043.png\n",
      "[Hispanic or Latino] order=(1, 0, 3, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\race\\Hispanic_or_Latino_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\race\\Hispanic_or_Latino_timeseries_to_2043.png\n",
      "[White] order=(1, 0, 0, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\race\\White_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\race\\White_timeseries_to_2043.png\n",
      "Consolidated CSV: D:\\arima project\\Task3\\Task 3\\results\\race\\ALL_GROUPS_forecasts_to_2043.csv\n",
      "Combined plot: D:\\arima project\\Task3\\Task 3\\results\\race\\COMBINED_timeseries_to_2043.png\n",
      "\n",
      "Sheet: census final\n",
      "Detected â†’ Year: 'Year' | AAMR: 'Age Adjusted Rate' | Group: 'Census Region'\n",
      "   Year    Group  AAMR\n",
      "0  1999  Midwest  6.58\n",
      "1  2000  Midwest  5.81\n",
      "2  2001  Midwest  5.22\n",
      "3  2002  Midwest  4.56\n",
      "4  2003  Midwest  4.07\n",
      "5  2004  Midwest  3.82\n",
      "[Midwest] order=(1, 0, 0, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\region\\Midwest_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\region\\Midwest_timeseries_to_2043.png\n",
      "[Northeast] order=(2, 0, 1, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\region\\Northeast_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\region\\Northeast_timeseries_to_2043.png\n",
      "[South] order=(1, 0, 2, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\region\\South_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\region\\South_timeseries_to_2043.png\n",
      "[West] order=(3, 0, 2, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\region\\West_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\region\\West_timeseries_to_2043.png\n",
      "Consolidated CSV: D:\\arima project\\Task3\\Task 3\\results\\region\\ALL_GROUPS_forecasts_to_2043.csv\n",
      "Combined plot: D:\\arima project\\Task3\\Task 3\\results\\region\\COMBINED_timeseries_to_2043.png\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Could not find any of: ['\\\\\\\\byear\\\\\\\\b', '^yr$', '\\\\\\\\bcalendar\\\\\\\\s*year\\\\\\\\b']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 388\u001b[0m\n\u001b[0;32m    385\u001b[0m out_dir\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# 1) Load & tidy\u001b[39;00m\n\u001b[1;32m--> 388\u001b[0m observed \u001b[38;5;241m=\u001b[39m load_observed_excel(FILE_PATH, sheet_name\u001b[38;5;241m=\u001b[39msheet_name, overall_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    390\u001b[0m \u001b[38;5;66;03m# 2) Fit & save per group (CSV + per-group plot)\u001b[39;00m\n\u001b[0;32m    391\u001b[0m fit_all_groups_and_save(observed, END_YEAR, out_dir, title_prefix\u001b[38;5;241m=\u001b[39mpretty_title)\n",
      "Cell \u001b[1;32mIn[16], line 186\u001b[0m, in \u001b[0;36mload_observed_excel\u001b[1;34m(path, sheet_name, overall_label)\u001b[0m\n\u001b[0;32m    183\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(xls, sheet_name\u001b[38;5;241m=\u001b[39mreal_sheet)\n\u001b[0;32m    184\u001b[0m df \u001b[38;5;241m=\u001b[39m _flatten_columns(df)\n\u001b[1;32m--> 186\u001b[0m ycol \u001b[38;5;241m=\u001b[39m find_year(df)\n\u001b[0;32m    187\u001b[0m tcol \u001b[38;5;241m=\u001b[39m find_aamr(df)\n\u001b[0;32m    188\u001b[0m gcol \u001b[38;5;241m=\u001b[39m find_group(df)  \u001b[38;5;66;03m# may be None\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 112\u001b[0m, in \u001b[0;36mfind_year\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_year\u001b[39m(df):  \u001b[38;5;66;03m# prefer 'Year'\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pick_col(df, [\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbyear\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^yr$\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbcalendar\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*year\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[16], line 108\u001b[0m, in \u001b[0;36m_pick_col\u001b[1;34m(df, patterns, required, exclude_regex)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m c\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required:\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find any of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatterns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Could not find any of: ['\\\\\\\\byear\\\\\\\\b', '^yr$', '\\\\\\\\bcalendar\\\\\\\\s*year\\\\\\\\b']\""
     ]
    }
   ],
   "source": [
    "# ==== ARIMA FORECASTS & PLOTS, BY SHEET (to 2043) ====\n",
    "# If needed first time:\n",
    "# !pip install pandas numpy matplotlib openpyxl statsmodels\n",
    "\n",
    "import os, re, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------- USER SETTINGS -----------\n",
    "FILE_PATH   = r\"D:\\arima project\\Task3\\Task 3\\cdc (IHD AND VFF) finals.xlsx\"\n",
    "OUTPUT_BASE = Path(r\"D:\\arima project\\Task3\\Task 3\\results\")\n",
    "END_YEAR    = 2043\n",
    "\n",
    "# Sheet list â†’ (sheet_name_as_you_see_it, folder_name, pretty_title)\n",
    "# (sheet name matching ignores case and extra spaces)\n",
    "RUN_SHEETS = [\n",
    "    (\"overall final\",        \"overall\",        \"Overall\"),\n",
    "    (\"Race final\",           \"race\",           \"Race / Ethnicity\"),\n",
    "    (\"census final\",         \"region\",         \"Census Regions\"),\n",
    "    (\"state final\",          \"state\",          \"States\"),\n",
    "    (\"urbanization final\",   \"urbanization\",   \"Urbanization\"),\n",
    "    (\"age group final\",      \"age\",            \"Age Groups\"),\n",
    "]\n",
    "\n",
    "# For very large categories (e.g., States), optionally limit combined chart\n",
    "# to the top N groups by the latest observed AAMR (None = show all).\n",
    "TOP_N_FOR_COMBINED = {\n",
    "    \"state\": 12  # show top 12 states; change or remove as you like\n",
    "}\n",
    "\n",
    "# Plot style (bold & large)\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (13, 7.6),\n",
    "    \"figure.dpi\": 160,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.25,\n",
    "    \"font.size\": 14,\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"axes.labelweight\": \"bold\",\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.titleweight\": \"bold\",\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"legend.frameon\": True,\n",
    "    \"legend.title_fontsize\": 13,\n",
    "    \"lines.linewidth\": 2.6,\n",
    "    \"lines.markersize\": 6.5,\n",
    "})\n",
    "def style_axes(ax):\n",
    "    ax.tick_params(axis=\"both\", labelsize=14, width=2.0, length=6)\n",
    "    for s in ax.spines.values():\n",
    "        s.set_linewidth(2.0)\n",
    "\n",
    "# ----------- HELPERS -----------\n",
    "def safe_name(s: str) -> str:\n",
    "    return re.sub(r\"[^a-zA-Z0-9_-]+\", \"_\", str(s)).strip(\"_\")\n",
    "\n",
    "def _normalize_name(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s).strip().lower())\n",
    "\n",
    "def _resolve_sheet_name(xls: pd.ExcelFile, requested: str) -> str:\n",
    "    \"\"\"Find sheet by name, ignoring case and extra whitespace; supports partial match.\"\"\"\n",
    "    req = _normalize_name(requested)\n",
    "    mapping = {_normalize_name(n): n for n in xls.sheet_names}\n",
    "    if req in mapping:\n",
    "        return mapping[req]\n",
    "    # partial contains match\n",
    "    for k, v in mapping.items():\n",
    "        if req in k:\n",
    "            return v\n",
    "    raise ValueError(f\"Sheet '{requested}' not found. Options: {xls.sheet_names}\")\n",
    "\n",
    "def _flatten_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Flatten multirow headers, normalize whitespace, and deduplicate duplicate names.\"\"\"\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [\n",
    "            \" \".join([str(x) for x in tup if (str(x) != \"nan\" and str(x).strip() != \"\")]).strip()\n",
    "            for tup in df.columns.to_list()\n",
    "        ]\n",
    "    df.columns = [re.sub(r\"\\s+\", \" \", str(c)).strip() for c in df.columns]\n",
    "    seen = {}\n",
    "    newcols = []\n",
    "    for c in df.columns:\n",
    "        if c in seen:\n",
    "            seen[c] += 1\n",
    "            newcols.append(f\"{c}.{seen[c]}\")\n",
    "        else:\n",
    "            seen[c] = 0\n",
    "            newcols.append(c)\n",
    "    df.columns = newcols\n",
    "    return df\n",
    "\n",
    "def _pick_col(df, patterns, required=True, exclude_regex=None):\n",
    "    low = {c: str(c).strip().lower() for c in df.columns}\n",
    "    for pat in patterns:\n",
    "        rx = re.compile(pat)\n",
    "        for c, lc in low.items():\n",
    "            if rx.search(lc):\n",
    "                if exclude_regex and re.search(exclude_regex, lc):\n",
    "                    continue\n",
    "                return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Could not find any of: {patterns}\")\n",
    "    return None\n",
    "\n",
    "def find_year(df):  # prefer 'Year'\n",
    "    return _pick_col(df, [r\"\\byear\\b\", r\"^yr$\", r\"\\bcalendar\\s*year\\b\"])\n",
    "\n",
    "def find_group(df):\n",
    "    \"\"\"Return the grouping column (Sex/Race/Age group/Region/Urbanization/State/Variable) or None for overall-only.\"\"\"\n",
    "    exclude = r\"age\\s*adjust|aamr|rate|ci|confidence|se|std|mean|median|total|overall\"\n",
    "    patterns = [\n",
    "        r\"\\bvariable\\b\",\n",
    "        r\"\\bage\\s*group(s)?\\b|age\\s*cat(egory|egories)?\\b|age\\s*grp\\b|age\\-group\",\n",
    "        r\"\\bgender\\b|\\bsex\\b\",\n",
    "        r\"\\brace\\b|ethnic|hispanic\",\n",
    "        r\"\\bregion\\b|census\",\n",
    "        r\"\\burban(ization)?\\b|rural\\b\",\n",
    "        r\"\\bstate\\b|^us state$|^state name$\",\n",
    "        r\"\\boverall\\b|^total$\"\n",
    "    ]\n",
    "    for pat in patterns:\n",
    "        try:\n",
    "            c = _pick_col(df, [pat], required=False, exclude_regex=exclude)\n",
    "            if c:\n",
    "                return c\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def find_aamr(df):\n",
    "    \"\"\"\n",
    "    Choose the most likely Age-Adjusted Rate column (numeric).\n",
    "    - prefer exact 'Age Adjusted Rate' / 'AAMR' / 'Age standardized rate'\n",
    "    - otherwise any column containing both 'age'+'adjust' and 'rate'\n",
    "    - if multiple candidates, pick the one with the largest variance\n",
    "    \"\"\"\n",
    "    low = {c: str(c).strip().lower() for c in df.columns}\n",
    "\n",
    "    candidates = []\n",
    "    exact_pats = [\n",
    "        r\"\\bage[-\\s]*adjust(ed)?\\s*rate\\b\",\n",
    "        r\"\\baamr\\b\",\n",
    "        r\"\\bage[-\\s]*standard(ized)?\\s*rate\\b\",\n",
    "    ]\n",
    "    for p in exact_pats:\n",
    "        try:\n",
    "            c = _pick_col(df, [p], required=False)\n",
    "            if c is not None:\n",
    "                candidates.append(c)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if not candidates:\n",
    "        # fallback: both 'age'+'adjust' and 'rate' in name, exclude crude\n",
    "        for c, lc in low.items():\n",
    "            if all(k in lc for k in [\"age\", \"adjust\"]) and \"rate\" in lc and \"crude\" not in lc:\n",
    "                candidates.append(c)\n",
    "\n",
    "    # keep only numeric\n",
    "    candidates = [c for c in candidates if pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "    if not candidates:\n",
    "        raise KeyError(\"No numeric Age-Adjusted Rate column found.\")\n",
    "\n",
    "    if len(candidates) == 1:\n",
    "        return candidates[0]\n",
    "\n",
    "    # pick the one with highest variance (more informative)\n",
    "    variances = {c: pd.to_numeric(df[c], errors=\"coerce\").var(skipna=True) for c in candidates}\n",
    "    return max(variances, key=variances.get)\n",
    "\n",
    "def load_observed_excel(path, sheet_name, overall_label=\"Overall\"):\n",
    "    \"\"\"Return tidy dataframe: Year, Group, AAMR.\"\"\"\n",
    "    xls = pd.ExcelFile(path)\n",
    "    real_sheet = _resolve_sheet_name(xls, sheet_name)\n",
    "\n",
    "    df = pd.read_excel(xls, sheet_name=real_sheet)\n",
    "    df = _flatten_columns(df)\n",
    "\n",
    "    ycol = find_year(df)\n",
    "    tcol = find_aamr(df)\n",
    "    gcol = find_group(df)  # may be None\n",
    "\n",
    "    df[ycol] = pd.to_numeric(df[ycol], errors=\"coerce\")\n",
    "    df[tcol] = pd.to_numeric(df[tcol], errors=\"coerce\")\n",
    "\n",
    "    if gcol and gcol == tcol:  # safety\n",
    "        gcol = None\n",
    "\n",
    "    if gcol is None:\n",
    "        tidy = (df[[ycol, tcol]]\n",
    "                .dropna(subset=[ycol, tcol])\n",
    "                .groupby(ycol, as_index=False)[tcol].mean()\n",
    "                .rename(columns={ycol: \"Year\", tcol: \"AAMR\"}))\n",
    "        tidy[\"Group\"] = overall_label\n",
    "        tidy = tidy[[\"Year\", \"Group\", \"AAMR\"]]\n",
    "    else:\n",
    "        df[gcol] = df[gcol].astype(str).str.strip()\n",
    "        tidy = (df[[ycol, gcol, tcol]]\n",
    "                .dropna(subset=[ycol, gcol, tcol])\n",
    "                .groupby([ycol, gcol], as_index=False)[tcol].mean()\n",
    "                .rename(columns={ycol: \"Year\", gcol: \"Group\", tcol: \"AAMR\"}))\n",
    "\n",
    "    tidy[\"Year\"] = tidy[\"Year\"].astype(int)\n",
    "    tidy = tidy.sort_values([\"Group\", \"Year\"]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"\\nSheet: {real_sheet}\")\n",
    "    print(f\"Detected â†’ Year: '{ycol}' | AAMR: '{tcol}' | Group: '{(gcol or overall_label)}'\")\n",
    "    print(tidy.head(6))\n",
    "    return tidy\n",
    "\n",
    "# ----------- ARIMA + FORECAST -----------\n",
    "def _sanitize_series_for_arima(y: pd.Series):\n",
    "    y = y.sort_index()\n",
    "    full = pd.Index(range(int(y.index.min()), int(y.index.max()) + 1), name=y.index.name)\n",
    "    y = y.reindex(full)\n",
    "    if y.isna().any():\n",
    "        y = y.interpolate(limit_direction=\"both\")\n",
    "    return y\n",
    "\n",
    "def select_arima_order(y):\n",
    "    best = None\n",
    "    for d in [0, 1, 2]:\n",
    "        for p in range(0, 4):\n",
    "            for q in range(0, 4):\n",
    "                if (p, d, q) == (0, 0, 0):\n",
    "                    continue\n",
    "                try:\n",
    "                    trend = \"n\" if d > 0 else \"c\"\n",
    "                    res = ARIMA(\n",
    "                        y, order=(p, d, q), trend=trend,\n",
    "                        enforce_stationarity=False, enforce_invertibility=False\n",
    "                    ).fit(method_kwargs={\"warn_convergence\": False})\n",
    "                    score = res.aic\n",
    "                    if (best is None) or (score < best[0]):\n",
    "                        best = (score, (p, d, q, trend), res)\n",
    "                except Exception:\n",
    "                    pass\n",
    "    if best is None:\n",
    "        res = ARIMA(y, order=(1, 1, 0), trend=\"n\",\n",
    "                    enforce_stationarity=False, enforce_invertibility=False\n",
    "                   ).fit(method_kwargs={\"warn_convergence\": False})\n",
    "        return (1, 1, 0, \"n\"), res\n",
    "    return best[1], best[2]\n",
    "\n",
    "def forecast_to(y, end_year, conf=0.95):\n",
    "    last_year = int(y.index.max())\n",
    "    steps = max(0, end_year - last_year)\n",
    "    if steps == 0:\n",
    "        raise ValueError(\"Observed series already extends to END_YEAR.\")\n",
    "    order, res = select_arima_order(y)\n",
    "    fc = res.get_forecast(steps=steps)\n",
    "    mean = fc.predicted_mean\n",
    "    ci   = fc.conf_int(alpha=1 - conf)\n",
    "    lo, hi = ci.iloc[:, 0], ci.iloc[:, 1]\n",
    "    yrs = list(range(last_year + 1, end_year + 1))\n",
    "    out = pd.DataFrame({\n",
    "        \"Year\": yrs,\n",
    "        \"Point.Forecast\": mean.values,\n",
    "        \"Lo.95\": lo.values,\n",
    "        \"Hi.95\": hi.values,\n",
    "        \"Order\": [f\"{order[0]},{order[1]},{order[2]} ({order[3]})\"] * steps\n",
    "    })\n",
    "    return order, out\n",
    "\n",
    "# ----------- FIT, SAVE, PLOT -----------\n",
    "def fit_all_groups_and_save(observed_df, end_year, out_dir: Path, title_prefix=\"Forecast\"):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    groups = sorted(observed_df[\"Group\"].unique())\n",
    "    all_rows = []\n",
    "    last_obs_year = int(observed_df[\"Year\"].max())\n",
    "\n",
    "    for g in groups:\n",
    "        sub = observed_df[observed_df[\"Group\"] == g].dropna(subset=[\"Year\", \"AAMR\"]).sort_values(\"Year\")\n",
    "        y = pd.Series(sub[\"AAMR\"].values, index=sub[\"Year\"].astype(int), name=\"AAMR\")\n",
    "        y = _sanitize_series_for_arima(y)\n",
    "\n",
    "        order, fc = forecast_to(y, end_year=end_year, conf=0.95)\n",
    "\n",
    "        # Save per-group CSV (2 decimals)\n",
    "        csv_path = out_dir / f\"{safe_name(g)}_forecast_to_{end_year}.csv\"\n",
    "        fc_out = fc.copy()\n",
    "        for c in [\"Point.Forecast\", \"Lo.95\", \"Hi.95\"]:\n",
    "            fc_out[c] = pd.to_numeric(fc_out[c], errors=\"coerce\").round(2)\n",
    "        fc_out.insert(0, \"Series\", g)\n",
    "        fc_out.to_csv(csv_path, index=False)\n",
    "        print(f\"[{g}] order={order}  -> CSV: {csv_path}\")\n",
    "\n",
    "        # Keep for consolidated\n",
    "        tmp = fc_out.copy(); tmp[\"Group\"] = g\n",
    "        all_rows.append(tmp)\n",
    "\n",
    "        # Per-group plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(y.index, y.values, marker=\"o\", label=f\"{g} (obs)\")\n",
    "        ln, = ax.plot(fc[\"Year\"], fc[\"Point.Forecast\"], linestyle=\"--\", marker=\"o\", label=f\"{g} (fc)\")\n",
    "        ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.14, color=ln.get_color(), label=\"95% CI (fc)\")\n",
    "        ax.axvline(x=last_obs_year + 0.5, linestyle=\":\", linewidth=2.0)\n",
    "        ax.set_title(f\"{title_prefix}: {g} â€” observed (â‰¤{last_obs_year}) & ARIMA forecast ({last_obs_year+1}â€“{end_year})\")\n",
    "        ax.set_xlabel(\"Year\"); ax.set_ylabel(\"AAMR (per 100,000)\")\n",
    "        ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n",
    "        style_axes(ax)\n",
    "        ax.legend(ncols=2)\n",
    "        plt.tight_layout()\n",
    "        png_path = out_dir / f\"{safe_name(g)}_timeseries_to_{end_year}.png\"\n",
    "        plt.savefig(png_path, dpi=300, bbox_inches=\"tight\"); plt.close()\n",
    "        print(\"   Plot:\", png_path)\n",
    "\n",
    "    if all_rows:\n",
    "        all_df = pd.concat(all_rows, ignore_index=True)\n",
    "        all_df.to_csv(out_dir / f\"ALL_GROUPS_forecasts_to_{end_year}.csv\", index=False)\n",
    "        print(\"Consolidated CSV:\", out_dir / f\"ALL_GROUPS_forecasts_to_{end_year}.csv\")\n",
    "\n",
    "def plot_combined(observed_df, out_dir: Path, end_year: int, title=\"Forecast\", top_n=None):\n",
    "    last_obs_year = int(observed_df[\"Year\"].max())\n",
    "    groups = sorted(observed_df[\"Group\"].unique())\n",
    "\n",
    "    # read saved forecasts for CI\n",
    "    fc_map = {}\n",
    "    for g in groups:\n",
    "        p = out_dir / f\"{safe_name(g)}_forecast_to_{end_year}.csv\"\n",
    "        if p.exists():\n",
    "            fc_map[g] = pd.read_csv(p)\n",
    "\n",
    "    # optionally limit to top N by last observed value\n",
    "    if top_n is not None and len(groups) > top_n:\n",
    "        latest = (observed_df.sort_values(\"Year\")\n",
    "                  .groupby(\"Group\", as_index=False)\n",
    "                  .apply(lambda d: d.iloc[-1][[\"Group\", \"AAMR\"]])\n",
    "                  .reset_index(drop=True))\n",
    "        keep = (latest.sort_values(\"AAMR\", ascending=False)\n",
    "                      .head(top_n)[\"Group\"].tolist())\n",
    "        groups = [g for g in groups if g in keep]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ci_legend_added = False\n",
    "\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key().get('color', None)\n",
    "    color_map = {}\n",
    "    if colors:\n",
    "        for i, g in enumerate(groups):\n",
    "            color_map[g] = colors[i % len(colors)]\n",
    "\n",
    "    for g in groups:\n",
    "        sub = observed_df[observed_df[\"Group\"] == g].copy().sort_values(\"Year\")\n",
    "        kwargs = {\"marker\": \"o\", \"label\": f\"{g} (obs)\"}\n",
    "        if g in color_map: kwargs[\"color\"] = color_map[g]\n",
    "        ax.plot(sub[\"Year\"], sub[\"AAMR\"], **kwargs)\n",
    "\n",
    "        if g in fc_map:\n",
    "            fc = fc_map[g]\n",
    "            kwargs_fc = {\"linestyle\": \"--\", \"marker\": \"o\", \"label\": f\"{g} (fc)\"}\n",
    "            if g in color_map: kwargs_fc[\"color\"] = color_map[g]\n",
    "            ln, = ax.plot(fc[\"Year\"], fc[\"Point.Forecast\"], **kwargs_fc)\n",
    "            # one legend entry for CI:\n",
    "            if not ci_legend_added:\n",
    "                ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.12,\n",
    "                                color=ln.get_color(), label=\"95% CI (fc)\")\n",
    "                ci_legend_added = True\n",
    "            else:\n",
    "                ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.12,\n",
    "                                color=ln.get_color())\n",
    "\n",
    "    ax.axvline(x=last_obs_year + 0.5, linestyle=\":\", linewidth=2.0)\n",
    "    ax.set_title(f\"{title}: observed (â‰¤{last_obs_year}) & ARIMA forecast ({last_obs_year+1}â€“{end_year})\")\n",
    "    ax.set_xlabel(\"Year\"); ax.set_ylabel(\"AAMR (per 100,000)\")\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n",
    "    style_axes(ax)\n",
    "    ax.legend(ncols=2)\n",
    "    ax.margins(x=0.02)\n",
    "    plt.tight_layout()\n",
    "    out = out_dir / f\"COMBINED_timeseries_to_{end_year}.png\"\n",
    "    plt.savefig(out, dpi=300, bbox_inches=\"tight\"); plt.close()\n",
    "    print(\"Combined plot:\", out)\n",
    "\n",
    "# ----------- RUN ALL SHEETS -----------\n",
    "for sheet_name, folder, pretty_title in RUN_SHEETS:\n",
    "    out_dir = OUTPUT_BASE / folder\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Load & tidy\n",
    "    observed = load_observed_excel(FILE_PATH, sheet_name=sheet_name, overall_label=\"Overall\")\n",
    "\n",
    "    # 2) Fit & save per group (CSV + per-group plot)\n",
    "    fit_all_groups_and_save(observed, END_YEAR, out_dir, title_prefix=pretty_title)\n",
    "\n",
    "    # 3) Combined plot (optionally limit very large categories)\n",
    "    topn = TOP_N_FOR_COMBINED.get(folder)\n",
    "    plot_combined(observed, out_dir, END_YEAR, title=pretty_title, top_n=topn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec5a4cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sheet: overall final\n",
      "Detected â†’ Year: 'Year' | AAMR: 'Age Adjusted Rate' | Group: 'Sex'\n",
      "   Year   Group  AAMR\n",
      "0  1999  Female  4.01\n",
      "1  2000  Female  3.46\n",
      "2  2001  Female  3.03\n",
      "3  2002  Female  2.68\n",
      "4  2003  Female  2.41\n",
      "5  2004  Female  2.09\n",
      "[Female] order=(1, 0, 1, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\overall\\Female_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\overall\\Female_timeseries_to_2043.png\n",
      "[Male] order=(2, 0, 0, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\overall\\Male_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\overall\\Male_timeseries_to_2043.png\n",
      "[overall] order=(1, 0, 0, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\overall\\overall_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\overall\\overall_timeseries_to_2043.png\n",
      "Consolidated CSV: D:\\arima project\\Task3\\Task 3\\results\\overall\\ALL_GROUPS_forecasts_to_2043.csv\n",
      "Combined plot: D:\\arima project\\Task3\\Task 3\\results\\overall\\COMBINED_timeseries_to_2043.png\n",
      "\n",
      "Sheet: Race final \n",
      "Detected â†’ Year: 'Year' | AAMR: 'Age Adjusted Rate' | Group: 'Hispanic Origin'\n",
      "   Year                             Group  AAMR\n",
      "0  1999  American Indian or Alaska Native  4.44\n",
      "1  2000  American Indian or Alaska Native  4.81\n",
      "2  2001  American Indian or Alaska Native  3.49\n",
      "3  2002  American Indian or Alaska Native  3.76\n",
      "4  2003  American Indian or Alaska Native  3.07\n",
      "5  2004  American Indian or Alaska Native  4.23\n",
      "[American Indian or Alaska Native] order=(1, 0, 3, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\race\\American_Indian_or_Alaska_Native_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\race\\American_Indian_or_Alaska_Native_timeseries_to_2043.png\n",
      "[Asian or Pacific Islander] order=(1, 0, 3, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\race\\Asian_or_Pacific_Islander_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\race\\Asian_or_Pacific_Islander_timeseries_to_2043.png\n",
      "[Black or African American] order=(3, 0, 2, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\race\\Black_or_African_American_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\race\\Black_or_African_American_timeseries_to_2043.png\n",
      "[Hispanic or Latino] order=(1, 0, 3, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\race\\Hispanic_or_Latino_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\race\\Hispanic_or_Latino_timeseries_to_2043.png\n",
      "[White] order=(1, 0, 0, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\race\\White_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\race\\White_timeseries_to_2043.png\n",
      "Consolidated CSV: D:\\arima project\\Task3\\Task 3\\results\\race\\ALL_GROUPS_forecasts_to_2043.csv\n",
      "Combined plot: D:\\arima project\\Task3\\Task 3\\results\\race\\COMBINED_timeseries_to_2043.png\n",
      "\n",
      "Sheet: census final\n",
      "Detected â†’ Year: 'Year' | AAMR: 'Age Adjusted Rate' | Group: 'Census Region'\n",
      "   Year    Group  AAMR\n",
      "0  1999  Midwest  6.58\n",
      "1  2000  Midwest  5.81\n",
      "2  2001  Midwest  5.22\n",
      "3  2002  Midwest  4.56\n",
      "4  2003  Midwest  4.07\n",
      "5  2004  Midwest  3.82\n",
      "[Midwest] order=(1, 0, 0, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\region\\Midwest_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\region\\Midwest_timeseries_to_2043.png\n",
      "[Northeast] order=(2, 0, 1, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\region\\Northeast_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\region\\Northeast_timeseries_to_2043.png\n",
      "[South] order=(1, 0, 2, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\region\\South_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\region\\South_timeseries_to_2043.png\n",
      "[West] order=(3, 0, 2, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\region\\West_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\region\\West_timeseries_to_2043.png\n",
      "Consolidated CSV: D:\\arima project\\Task3\\Task 3\\results\\region\\ALL_GROUPS_forecasts_to_2043.csv\n",
      "Combined plot: D:\\arima project\\Task3\\Task 3\\results\\region\\COMBINED_timeseries_to_2043.png\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\pc\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: None",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 378\u001b[0m\n\u001b[0;32m    375\u001b[0m out_dir \u001b[38;5;241m=\u001b[39m OUTPUT_BASE \u001b[38;5;241m/\u001b[39m folder\n\u001b[0;32m    376\u001b[0m out_dir\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 378\u001b[0m observed \u001b[38;5;241m=\u001b[39m load_observed_excel(FILE_PATH, sheet_name\u001b[38;5;241m=\u001b[39msheet_name, overall_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    379\u001b[0m fit_all_groups_and_save(observed, END_YEAR, out_dir, title_prefix\u001b[38;5;241m=\u001b[39mpretty_title)\n\u001b[0;32m    380\u001b[0m topn \u001b[38;5;241m=\u001b[39m TOP_N_FOR_COMBINED\u001b[38;5;241m.\u001b[39mget(folder)\n",
      "Cell \u001b[1;32mIn[17], line 183\u001b[0m, in \u001b[0;36mload_observed_excel\u001b[1;34m(path, sheet_name, overall_label)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sex_cols:\n\u001b[0;32m    181\u001b[0m     gcol \u001b[38;5;241m=\u001b[39m sex_cols[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 183\u001b[0m df[ycol] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[ycol], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    184\u001b[0m df[tcol] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[tcol], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gcol \u001b[38;5;129;01mand\u001b[39;00m gcol \u001b[38;5;241m==\u001b[39m tcol:\n",
      "File \u001b[1;32mc:\\Users\\pc\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\pc\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "# ==== ARIMA FORECASTS & PLOTS TO 2043 (robust to 'Year Code' & Sex in 'overall final') ====\n",
    "# !pip install pandas numpy matplotlib openpyxl statsmodels\n",
    "\n",
    "import re, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------- USER SETTINGS -----------\n",
    "FILE_PATH   = r\"D:\\arima project\\Task3\\Task 3\\cdc (IHD AND VFF) finals.xlsx\"\n",
    "OUTPUT_BASE = Path(r\"D:\\arima project\\Task3\\Task 3\\results\")\n",
    "END_YEAR    = 2043\n",
    "\n",
    "# Sheet list â†’ (sheet_name_as_you_see_it, folder_name, pretty_title)\n",
    "RUN_SHEETS = [\n",
    "    (\"overall final\",        \"overall\",        \"Overall\"),\n",
    "    (\"Race final\",           \"race\",           \"Race / Ethnicity\"),\n",
    "    (\"census final\",         \"region\",         \"Census Regions\"),\n",
    "    (\"state final\",          \"state\",          \"States\"),\n",
    "    (\"urbanization final\",   \"urbanization\",   \"Urbanization\"),\n",
    "    (\"age group final\",      \"age\",            \"Age Groups\"),\n",
    "]\n",
    "\n",
    "TOP_N_FOR_COMBINED = {\n",
    "    \"state\": 12,   # show top 12 states in combined plot; set None to show all\n",
    "}\n",
    "\n",
    "# ----------- PLOT STYLE -----------\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (13, 7.6),\n",
    "    \"figure.dpi\": 160,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.25,\n",
    "    \"font.size\": 14,\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"axes.labelweight\": \"bold\",\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.titleweight\": \"bold\",\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"legend.frameon\": True,\n",
    "    \"legend.title_fontsize\": 13,\n",
    "    \"lines.linewidth\": 2.6,\n",
    "    \"lines.markersize\": 6.5,\n",
    "})\n",
    "def style_axes(ax):\n",
    "    ax.tick_params(axis=\"both\", labelsize=14, width=2.0, length=6)\n",
    "    for s in ax.spines.values():\n",
    "        s.set_linewidth(2.0)\n",
    "\n",
    "# ----------- HELPERS -----------\n",
    "def safe_name(s: str) -> str:\n",
    "    return re.sub(r\"[^a-zA-Z0-9_-]+\", \"_\", str(s)).strip(\"_\")\n",
    "\n",
    "def _normalize_name(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s).strip().lower())\n",
    "\n",
    "def _resolve_sheet_name(xls: pd.ExcelFile, requested: str) -> str:\n",
    "    \"\"\"Find sheet by name, ignoring case and extra whitespace; supports contains-match.\"\"\"\n",
    "    req = _normalize_name(requested)\n",
    "    mapping = {_normalize_name(n): n for n in xls.sheet_names}\n",
    "    if req in mapping:\n",
    "        return mapping[req]\n",
    "    for k, v in mapping.items():\n",
    "        if req in k:\n",
    "            return v\n",
    "    raise ValueError(f\"Sheet '{requested}' not found. Options: {xls.sheet_names}\")\n",
    "\n",
    "def _flatten_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [\n",
    "            \" \".join([str(x) for x in tup if (str(x) != \"nan\" and str(x).strip() != \"\")]).strip()\n",
    "            for tup in df.columns.to_list()\n",
    "        ]\n",
    "    df.columns = [re.sub(r\"\\s+\", \" \", str(c)).strip() for c in df.columns]\n",
    "    # de-duplicate\n",
    "    seen = {}\n",
    "    newcols = []\n",
    "    for c in df.columns:\n",
    "        if c in seen:\n",
    "            seen[c] += 1\n",
    "            newcols.append(f\"{c}.{seen[c]}\")\n",
    "        else:\n",
    "            seen[c] = 0\n",
    "            newcols.append(c)\n",
    "    df.columns = newcols\n",
    "    return df\n",
    "\n",
    "def _pick_col(df, patterns, required=True, exclude_regex=None):\n",
    "    low = {c: str(c).strip().lower() for c in df.columns}\n",
    "    for pat in patterns:\n",
    "        rx = re.compile(pat)\n",
    "        for c, lc in low.items():\n",
    "            if rx.search(lc):\n",
    "                if exclude_regex and re.search(exclude_regex, lc):\n",
    "                    continue\n",
    "                return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Could not find any of: {patterns}\")\n",
    "    return None\n",
    "\n",
    "def find_year(df):\n",
    "    # common names first\n",
    "    try: return _pick_col(df, [r\"\\byear\\b\", r\"^yr$\", r\"\\bcalendar\\s*year\\b\"], required=False)\n",
    "    except: pass\n",
    "    # accept Year Code explicitly\n",
    "    try: return _pick_col(df, [r\"\\byear\\s*code\\b\"], required=False)\n",
    "    except: pass\n",
    "    # fallback: any column that contains 'year'\n",
    "    for c in df.columns:\n",
    "        if \"year\" in str(c).strip().lower():\n",
    "            return c\n",
    "    raise KeyError(r\"Could not find any year column (e.g., 'Year', 'Year Code').\")\n",
    "\n",
    "def find_group(df):\n",
    "    \"\"\"Prefer a true grouping column (Sex, Race, Age group, Region, Urbanization, State, Variable).\"\"\"\n",
    "    exclude = r\"age\\s*adjust|aamr|rate|ci|confidence|se|std|mean|median|total|overall\"\n",
    "    patterns = [\n",
    "        r\"\\bvariable\\b\",\n",
    "        r\"\\bage\\s*group(s)?\\b|age\\s*cat(egory|egories)?\\b|age\\s*grp\\b|age\\-group\",\n",
    "        r\"\\bgender\\b|\\bsex\\b\",\n",
    "        r\"\\brace\\b|ethnic|hispanic\",\n",
    "        r\"\\bregion\\b|census\",\n",
    "        r\"\\burban(ization)?\\b|rural\\b\",\n",
    "        r\"\\bstate\\b|^us state$|^state name$\",\n",
    "    ]\n",
    "    for pat in patterns:\n",
    "        try:\n",
    "            c = _pick_col(df, [pat], required=False, exclude_regex=exclude)\n",
    "            if c:\n",
    "                return c\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def find_aamr(df):\n",
    "    # candidates by name\n",
    "    exact_pats = [\n",
    "        r\"\\bage[-\\s]*adjust(ed)?\\s*rate\\b\",\n",
    "        r\"\\baamr\\b\",\n",
    "        r\"\\bage[-\\s]*standard(ized)?\\s*rate\\b\",\n",
    "    ]\n",
    "    candidates = []\n",
    "    for p in exact_pats:\n",
    "        try:\n",
    "            c = _pick_col(df, [p], required=False)\n",
    "            if c is not None: candidates.append(c)\n",
    "        except: pass\n",
    "    if not candidates:\n",
    "        # both 'age'+'adjust' and 'rate', but not crude\n",
    "        for c in df.columns:\n",
    "            lc = str(c).strip().lower()\n",
    "            if all(k in lc for k in [\"age\",\"adjust\"]) and \"rate\" in lc and \"crude\" not in lc:\n",
    "                candidates.append(c)\n",
    "    # keep numeric only\n",
    "    candidates = [c for c in candidates if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if not candidates:\n",
    "        raise KeyError(\"No numeric Age-Adjusted Rate column found.\")\n",
    "    if len(candidates) == 1: return candidates[0]\n",
    "    # choose with highest variance\n",
    "    variances = {c: pd.to_numeric(df[c], errors=\"coerce\").var(skipna=True) for c in candidates}\n",
    "    return max(variances, key=variances.get)\n",
    "\n",
    "def load_observed_excel(path, sheet_name, overall_label=\"Overall\"):\n",
    "    xls = pd.ExcelFile(path)\n",
    "    real_sheet = _resolve_sheet_name(xls, sheet_name)\n",
    "    df = pd.read_excel(xls, sheet_name=real_sheet)\n",
    "    df = _flatten_columns(df)\n",
    "\n",
    "    ycol = find_year(df)\n",
    "    tcol = find_aamr(df)\n",
    "    gcol = find_group(df)  # may be None\n",
    "\n",
    "    # SPECIAL: if 'Sex' exists, use it (ensures 'overall final' splits into Male/Female)\n",
    "    sex_cols = [c for c in df.columns if _normalize_name(c) == \"sex\"]\n",
    "    if sex_cols:\n",
    "        gcol = sex_cols[0]\n",
    "\n",
    "    df[ycol] = pd.to_numeric(df[ycol], errors=\"coerce\")\n",
    "    df[tcol] = pd.to_numeric(df[tcol], errors=\"coerce\")\n",
    "\n",
    "    if gcol and gcol == tcol:\n",
    "        gcol = None\n",
    "\n",
    "    if gcol is None:\n",
    "        tidy = (df[[ycol, tcol]]\n",
    "                .dropna(subset=[ycol, tcol])\n",
    "                .groupby(ycol, as_index=False)[tcol].mean()\n",
    "                .rename(columns={ycol:\"Year\", tcol:\"AAMR\"}))\n",
    "        tidy[\"Group\"] = overall_label\n",
    "        tidy = tidy[[\"Year\",\"Group\",\"AAMR\"]]\n",
    "    else:\n",
    "        df[gcol] = df[gcol].astype(str).str.strip()\n",
    "        tidy = (df[[ycol, gcol, tcol]]\n",
    "                .dropna(subset=[ycol, gcol, tcol])\n",
    "                .groupby([ycol, gcol], as_index=False)[tcol].mean()\n",
    "                .rename(columns={ycol:\"Year\", gcol:\"Group\", tcol:\"AAMR\"}))\n",
    "\n",
    "    tidy[\"Year\"] = tidy[\"Year\"].astype(int)\n",
    "    tidy = tidy.sort_values([\"Group\",\"Year\"]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"\\nSheet: {real_sheet}\")\n",
    "    print(f\"Detected â†’ Year: '{ycol}' | AAMR: '{tcol}' | Group: '{(gcol or overall_label)}'\")\n",
    "    print(tidy.head(6))\n",
    "    return tidy\n",
    "\n",
    "# ----------- ARIMA + FORECAST -----------\n",
    "def _sanitize_series_for_arima(y: pd.Series):\n",
    "    y = y.sort_index()\n",
    "    full = pd.Index(range(int(y.index.min()), int(y.index.max()) + 1), name=y.index.name)\n",
    "    y = y.reindex(full)\n",
    "    if y.isna().any():\n",
    "        y = y.interpolate(limit_direction=\"both\")\n",
    "    return y\n",
    "\n",
    "def select_arima_order(y):\n",
    "    best = None\n",
    "    for d in [0,1,2]:\n",
    "        for p in range(0,4):\n",
    "            for q in range(0,4):\n",
    "                if (p,d,q) == (0,0,0):\n",
    "                    continue\n",
    "                try:\n",
    "                    trend = \"n\" if d>0 else \"c\"\n",
    "                    res = ARIMA(y, order=(p,d,q), trend=trend,\n",
    "                                enforce_stationarity=False, enforce_invertibility=False\n",
    "                               ).fit(method_kwargs={\"warn_convergence\":False})\n",
    "                    score = res.aic\n",
    "                    if (best is None) or (score < best[0]):\n",
    "                        best = (score, (p,d,q,trend), res)\n",
    "                except Exception:\n",
    "                    pass\n",
    "    if best is None:\n",
    "        res = ARIMA(y, order=(1,1,0), trend=\"n\",\n",
    "                    enforce_stationarity=False, enforce_invertibility=False\n",
    "                   ).fit(method_kwargs={\"warn_convergence\":False})\n",
    "        return (1,1,0,\"n\"), res\n",
    "    return best[1], best[2]\n",
    "\n",
    "def forecast_to(y, end_year, conf=0.95):\n",
    "    last_year = int(y.index.max())\n",
    "    steps = max(0, end_year - last_year)\n",
    "    if steps == 0:\n",
    "        raise ValueError(\"Observed series already extends to END_YEAR.\")\n",
    "    order, res = select_arima_order(y)\n",
    "    fc = res.get_forecast(steps=steps)\n",
    "    mean = fc.predicted_mean\n",
    "    ci   = fc.conf_int(alpha=1-conf)\n",
    "    lo, hi = ci.iloc[:,0], ci.iloc[:,1]\n",
    "    yrs = list(range(last_year+1, end_year+1))\n",
    "    out = pd.DataFrame({\n",
    "        \"Year\": yrs,\n",
    "        \"Point.Forecast\": mean.values,\n",
    "        \"Lo.95\": lo.values,\n",
    "        \"Hi.95\": hi.values,\n",
    "        \"Order\": [f\"{order[0]},{order[1]},{order[2]} ({order[3]})\"]*steps\n",
    "    })\n",
    "    return order, out\n",
    "\n",
    "# ----------- FIT, SAVE, PLOT -----------\n",
    "def fit_all_groups_and_save(observed_df, end_year, out_dir: Path, title_prefix=\"Forecast\"):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    groups = sorted(observed_df[\"Group\"].unique())\n",
    "    all_rows = []\n",
    "    last_obs_year = int(observed_df[\"Year\"].max())\n",
    "\n",
    "    for g in groups:\n",
    "        sub = observed_df[observed_df[\"Group\"]==g].dropna(subset=[\"Year\",\"AAMR\"]).sort_values(\"Year\")\n",
    "        y = pd.Series(sub[\"AAMR\"].values, index=sub[\"Year\"].astype(int), name=\"AAMR\")\n",
    "        y = _sanitize_series_for_arima(y)\n",
    "\n",
    "        order, fc = forecast_to(y, end_year=end_year, conf=0.95)\n",
    "\n",
    "        # per-group CSV (2 decimals)\n",
    "        csv_path = out_dir / f\"{safe_name(g)}_forecast_to_{end_year}.csv\"\n",
    "        fc_out = fc.copy()\n",
    "        for c in [\"Point.Forecast\",\"Lo.95\",\"Hi.95\"]:\n",
    "            fc_out[c] = pd.to_numeric(fc_out[c], errors=\"coerce\").round(2)\n",
    "        fc_out.insert(0, \"Series\", g)\n",
    "        fc_out.to_csv(csv_path, index=False)\n",
    "        print(f\"[{g}] order={order}  -> CSV: {csv_path}\")\n",
    "\n",
    "        # store for consolidated\n",
    "        tmp = fc_out.copy(); tmp[\"Group\"] = g\n",
    "        all_rows.append(tmp)\n",
    "\n",
    "        # per-group plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(y.index, y.values, marker=\"o\", label=f\"{g} (obs)\")\n",
    "        ln, = ax.plot(fc[\"Year\"], fc[\"Point.Forecast\"], linestyle=\"--\", marker=\"o\", label=f\"{g} (fc)\")\n",
    "        ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.14, color=ln.get_color(), label=\"95% CI (fc)\")\n",
    "        ax.axvline(x=last_obs_year+0.5, linestyle=\":\", linewidth=2.0)\n",
    "        ax.set_title(f\"{title_prefix}: {g} â€” observed (â‰¤{last_obs_year}) & ARIMA forecast ({last_obs_year+1}â€“{end_year})\")\n",
    "        ax.set_xlabel(\"Year\"); ax.set_ylabel(\"AAMR (per 100,000)\")\n",
    "        ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n",
    "        style_axes(ax)\n",
    "        ax.legend(ncols=2)\n",
    "        plt.tight_layout()\n",
    "        png_path = out_dir / f\"{safe_name(g)}_timeseries_to_{end_year}.png\"\n",
    "        plt.savefig(png_path, dpi=300, bbox_inches=\"tight\"); plt.close()\n",
    "        print(\"   Plot:\", png_path)\n",
    "\n",
    "    if all_rows:\n",
    "        all_df = pd.concat(all_rows, ignore_index=True)\n",
    "        all_df.to_csv(out_dir / f\"ALL_GROUPS_forecasts_to_{end_year}.csv\", index=False)\n",
    "        print(\"Consolidated CSV:\", out_dir / f\"ALL_GROUPS_forecasts_to_{end_year}.csv\")\n",
    "\n",
    "def plot_combined(observed_df, out_dir:Path, end_year:int, title=\"Forecast\", top_n=None):\n",
    "    last_obs_year = int(observed_df[\"Year\"].max())\n",
    "    groups = sorted(observed_df[\"Group\"].unique())\n",
    "\n",
    "    # read saved forecasts\n",
    "    fc_map = {}\n",
    "    for g in groups:\n",
    "        p = out_dir / f\"{safe_name(g)}_forecast_to_{end_year}.csv\"\n",
    "        if p.exists():\n",
    "            fc_map[g] = pd.read_csv(p)\n",
    "\n",
    "    # limit to top N by latest observed value (if requested)\n",
    "    if top_n is not None and len(groups) > top_n:\n",
    "        latest = (observed_df.sort_values(\"Year\")\n",
    "                  .groupby(\"Group\", as_index=False)\n",
    "                  .apply(lambda d: d.iloc[-1][[\"Group\",\"AAMR\"]])\n",
    "                  .reset_index(drop=True))\n",
    "        keep = (latest.sort_values(\"AAMR\", ascending=False)\n",
    "                      .head(top_n)[\"Group\"].tolist())\n",
    "        groups = [g for g in groups if g in keep]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ci_legend_added = False\n",
    "\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key().get('color', None)\n",
    "    color_map = {}\n",
    "    if colors:\n",
    "        for i, g in enumerate(groups):\n",
    "            color_map[g] = colors[i % len(colors)]\n",
    "\n",
    "    for g in groups:\n",
    "        sub = observed_df[observed_df[\"Group\"]==g].copy().sort_values(\"Year\")\n",
    "        kw_obs = {\"marker\": \"o\", \"label\": f\"{g} (obs)\"}\n",
    "        if g in color_map: kw_obs[\"color\"] = color_map[g]\n",
    "        ax.plot(sub[\"Year\"], sub[\"AAMR\"], **kw_obs)\n",
    "\n",
    "        if g in fc_map:\n",
    "            fc = fc_map[g]\n",
    "            kw_fc = {\"linestyle\": \"--\", \"marker\": \"o\", \"label\": f\"{g} (fc)\"}\n",
    "            if g in color_map: kw_fc[\"color\"] = color_map[g]\n",
    "            ln, = ax.plot(fc[\"Year\"], fc[\"Point.Forecast\"], **kw_fc)\n",
    "            if not ci_legend_added:\n",
    "                ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.12,\n",
    "                                color=ln.get_color(), label=\"95% CI (fc)\")\n",
    "                ci_legend_added = True\n",
    "            else:\n",
    "                ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.12,\n",
    "                                color=ln.get_color())\n",
    "\n",
    "    ax.axvline(x=last_obs_year+0.5, linestyle=\":\", linewidth=2.0)\n",
    "    ax.set_title(f\"{title}: observed (â‰¤{last_obs_year}) & ARIMA forecast ({last_obs_year+1}â€“{end_year})\")\n",
    "    ax.set_xlabel(\"Year\"); ax.set_ylabel(\"AAMR (per 100,000)\")\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n",
    "    style_axes(ax)\n",
    "    ax.legend(ncols=2)\n",
    "    ax.margins(x=0.02)\n",
    "    plt.tight_layout()\n",
    "    out = out_dir / f\"COMBINED_timeseries_to_{end_year}.png\"\n",
    "    plt.savefig(out, dpi=300, bbox_inches=\"tight\"); plt.close()\n",
    "    print(\"Combined plot:\", out)\n",
    "\n",
    "# ----------- RUN ALL SHEETS -----------\n",
    "for sheet_name, folder, pretty_title in RUN_SHEETS:\n",
    "    out_dir = OUTPUT_BASE / folder\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    observed = load_observed_excel(FILE_PATH, sheet_name=sheet_name, overall_label=\"Overall\")\n",
    "    fit_all_groups_and_save(observed, END_YEAR, out_dir, title_prefix=pretty_title)\n",
    "    topn = TOP_N_FOR_COMBINED.get(folder)\n",
    "    plot_combined(observed, out_dir, END_YEAR, title=pretty_title, top_n=topn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "676f9fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sheet: urbanization final\n",
      "Detected â†’ Year: 'Year' | AAMR: 'Age Adjusted Rate' | Group: 'urbanization'\n",
      "   Year  Group  AAMR\n",
      "0  1999  Rural  7.20\n",
      "1  2000  Rural  6.44\n",
      "2  2001  Rural  5.62\n",
      "3  2002  Rural  5.09\n",
      "4  2003  Rural  4.49\n",
      "5  2004  Rural  3.88\n",
      "[Rural] order=(1, 0, 2, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\urbanization\\Rural_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\urbanization\\Rural_timeseries_to_2043.png\n",
      "[Urban] order=(2, 0, 1, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\urbanization\\Urban_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\urbanization\\Urban_timeseries_to_2043.png\n",
      "Consolidated CSV: D:\\arima project\\Task3\\Task 3\\results\\urbanization\\ALL_GROUPS_forecasts_to_2043.csv\n",
      "Combined plot: D:\\arima project\\Task3\\Task 3\\results\\urbanization\\COMBINED_timeseries_to_2043.png\n",
      "\n",
      "Sheet: age group final\n",
      "Detected â†’ Year: 'Year' | AAMR: 'Age Adjusted Rate' | Group: 'Age group'\n",
      "   Year         Group  AAMR\n",
      "0  1999  middle adult  4.10\n",
      "1  2000  middle adult  3.49\n",
      "2  2001  middle adult  3.05\n",
      "3  2002  middle adult  2.91\n",
      "4  2003  middle adult  2.52\n",
      "5  2004  middle adult  2.32\n",
      "[middle adult] order=(1, 0, 1, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\age\\middle_adult_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\age\\middle_adult_timeseries_to_2043.png\n",
      "[old adult] order=(1, 0, 1, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\age\\old_adult_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\age\\old_adult_timeseries_to_2043.png\n",
      "[young adult] order=(1, 0, 0, 'c')  -> CSV: D:\\arima project\\Task3\\Task 3\\results\\age\\young_adult_forecast_to_2043.csv\n",
      "   Plot: D:\\arima project\\Task3\\Task 3\\results\\age\\young_adult_timeseries_to_2043.png\n",
      "Consolidated CSV: D:\\arima project\\Task3\\Task 3\\results\\age\\ALL_GROUPS_forecasts_to_2043.csv\n",
      "Combined plot: D:\\arima project\\Task3\\Task 3\\results\\age\\COMBINED_timeseries_to_2043.png\n"
     ]
    }
   ],
   "source": [
    "# ==== ARIMA FORECASTS & PLOTS â†’ 2043 (robust + bold + 95% CI) ====\n",
    "# If first time:\n",
    "# !pip install pandas numpy matplotlib openpyxl statsmodels\n",
    "\n",
    "import re, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- USER SETTINGS ----------------\n",
    "FILE_PATH   = r\"D:\\arima project\\Task3\\Task 3\\cdc (IHD AND VFF) finals.xlsx\"\n",
    "OUTPUT_BASE = Path(r\"D:\\arima project\\Task3\\Task 3\\results\")\n",
    "END_YEAR    = 2043\n",
    "\n",
    "# Done: overall / race / region. Remaining commonly are: state, urbanization, age.\n",
    "# You can run all; it will overwrite safely.\n",
    "RUN_SHEETS = [\n",
    "\n",
    "    (\"urbanization final\",   \"urbanization\",   \"Urbanization\"),\n",
    "    (\"age group final\",      \"age\",            \"Age Groups\"),\n",
    "]\n",
    "\n",
    "# Limit combined chart to top-N by latest observed AAMR (e.g., many states).\n",
    "TOP_N_FOR_COMBINED = {\n",
    "    \"state\": 12,   # set None to show all\n",
    "}\n",
    "\n",
    "# ---------------- PLOT STYLE ----------------\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (13, 7.6),\n",
    "    \"figure.dpi\": 160,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.25,\n",
    "    \"font.size\": 14,\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"axes.labelweight\": \"bold\",\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.titleweight\": \"bold\",\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"legend.frameon\": True,\n",
    "    \"legend.title_fontsize\": 13,\n",
    "    \"lines.linewidth\": 2.6,\n",
    "    \"lines.markersize\": 6.5,\n",
    "})\n",
    "def style_axes(ax):\n",
    "    ax.tick_params(axis=\"both\", labelsize=14, width=2.0, length=6)\n",
    "    for s in ax.spines.values():\n",
    "        s.set_linewidth(2.0)\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def safe_name(s: str) -> str:\n",
    "    return re.sub(r\"[^a-zA-Z0-9_-]+\", \"_\", str(s)).strip(\"_\")\n",
    "\n",
    "def _normalize_name(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s).strip().lower())\n",
    "\n",
    "def _resolve_sheet_name(xls: pd.ExcelFile, requested: str) -> str:\n",
    "    \"\"\"Find sheet ignoring case/extra spaces; supports contains-match.\"\"\"\n",
    "    req = _normalize_name(requested)\n",
    "    mapping = {_normalize_name(n): n for n in xls.sheet_names}\n",
    "    if req in mapping:\n",
    "        return mapping[req]\n",
    "    for k, v in mapping.items():\n",
    "        if req in k:\n",
    "            return v\n",
    "    raise ValueError(f\"Sheet '{requested}' not found. Options: {xls.sheet_names}\")\n",
    "\n",
    "def _flatten_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Flatten multirow headers, normalize whitespace, deduplicate names.\"\"\"\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [\n",
    "            \" \".join([str(x) for x in tup if (str(x) != \"nan\" and str(x).strip() != \"\")]).strip()\n",
    "            for tup in df.columns.to_list()\n",
    "        ]\n",
    "    df.columns = [re.sub(r\"\\s+\", \" \", str(c)).strip() for c in df.columns]\n",
    "    seen, newcols = {}, []\n",
    "    for c in df.columns:\n",
    "        if c in seen:\n",
    "            seen[c] += 1; newcols.append(f\"{c}.{seen[c]}\")\n",
    "        else:\n",
    "            seen[c] = 0;  newcols.append(c)\n",
    "    df.columns = newcols\n",
    "    return df\n",
    "\n",
    "def _pick_col(df, patterns, required=True, exclude_regex=None):\n",
    "    low = {c: str(c).strip().lower() for c in df.columns}\n",
    "    for pat in patterns:\n",
    "        rx = re.compile(pat)\n",
    "        for c, lc in low.items():\n",
    "            if rx.search(lc):\n",
    "                if exclude_regex and re.search(exclude_regex, lc):\n",
    "                    continue\n",
    "                return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Could not find any of: {patterns}\")\n",
    "    return None\n",
    "\n",
    "def find_year(df):\n",
    "    \"\"\"\n",
    "    Robust: 'Year', 'Year Code', 'Calendar Year', or any header containing 'year'.\n",
    "    Avoid returning None; raise with clear message if not found.\n",
    "    \"\"\"\n",
    "    # exact-ish first\n",
    "    y = _pick_col(df, [r\"\\byear\\b\", r\"^yr$\", r\"\\bcalendar\\s*year\\b\"], required=False)\n",
    "    if y: return y\n",
    "    y = _pick_col(df, [r\"\\byear\\s*code\\b\", r\"\\bdata\\s*year\\b\", r\"\\byear\\s*of\\s*death\\b\"], required=False)\n",
    "    if y: return y\n",
    "    # fallback: any column containing 'year'\n",
    "    for c in df.columns:\n",
    "        if \"year\" in str(c).strip().lower():\n",
    "            return c\n",
    "    # last resort: helpful error\n",
    "    raise KeyError(\n",
    "        \"No year column found. Expected headers like 'Year', 'Year Code', 'Calendar Year'. \"\n",
    "        f\"Available columns: {list(df.columns)}\"\n",
    "    )\n",
    "\n",
    "def find_group(df):\n",
    "    \"\"\"Return grouping col (Sex, Race, Age group, Region, Urbanization, State, Variable) or None.\"\"\"\n",
    "    exclude = r\"age\\s*adjust|aamr|rate|ci|confidence|se|std|mean|median|total|overall\"\n",
    "    patterns = [\n",
    "        r\"\\bvariable\\b\",\n",
    "        r\"\\bage\\s*group(s)?\\b|age\\s*cat(egory|egories)?\\b|age\\s*grp\\b|age\\-group\",\n",
    "        r\"\\bgender\\b|\\bsex\\b\",\n",
    "        r\"\\brace\\b|ethnic|hispanic\",\n",
    "        r\"\\bregion\\b|census\",\n",
    "        r\"\\burban(ization)?\\b|metro|non[-\\s]?metro|rural\\b\",\n",
    "        r\"\\bstate\\b|^us state$|^state name$\",\n",
    "    ]\n",
    "    for pat in patterns:\n",
    "        c = _pick_col(df, [pat], required=False, exclude_regex=exclude)\n",
    "        if c:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def find_aamr(df):\n",
    "    \"\"\"\n",
    "    Choose Age-Adjusted Rate column:\n",
    "    - exact names first (Age Adjusted Rate / AAMR / Age standardized rate / Age-adjusted death rate)\n",
    "    - else any column name containing 'age' & 'adjust' & 'rate' (not 'crude')\n",
    "    - among candidates, pick numeric with largest variance\n",
    "    \"\"\"\n",
    "    exact_pats = [\n",
    "        r\"\\bage[-\\s]*adjust(ed)?\\s*rate\\b\",\n",
    "        r\"\\bage[-\\s]*adjust(ed)?\\s*death\\s*rate\\b\",\n",
    "        r\"\\baamr\\b\",\n",
    "        r\"\\bage[-\\s]*standard(ized)?\\s*rate\\b\",\n",
    "    ]\n",
    "    candidates = []\n",
    "    for p in exact_pats:\n",
    "        c = _pick_col(df, [p], required=False)\n",
    "        if c: candidates.append(c)\n",
    "\n",
    "    if not candidates:\n",
    "        for c in df.columns:\n",
    "            lc = str(c).strip().lower()\n",
    "            if all(k in lc for k in [\"age\",\"adjust\"]) and \"rate\" in lc and \"crude\" not in lc:\n",
    "                candidates.append(c)\n",
    "\n",
    "    # numeric only\n",
    "    num_cands = [c for c in candidates if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if not num_cands:\n",
    "        raise KeyError(\n",
    "            \"No numeric Age-Adjusted Rate column found. \"\n",
    "            f\"Tried candidates: {candidates} | Columns: {list(df.columns)}\"\n",
    "        )\n",
    "\n",
    "    if len(num_cands) == 1:\n",
    "        return num_cands[0]\n",
    "\n",
    "    variances = {c: pd.to_numeric(df[c], errors=\"coerce\").var(skipna=True) for c in num_cands}\n",
    "    return max(variances, key=variances.get)\n",
    "\n",
    "def _rate_axis_label_from_header(colname: str) -> str:\n",
    "    s = str(colname).lower()\n",
    "    if \"1,000,000\" in colname or \"per 1,000,000\" in s or \"per million\" in s:\n",
    "        return \"AAMR (per 1,000,000)\"\n",
    "    return \"AAMR (per 100,000)\"\n",
    "\n",
    "def load_observed_excel(path, sheet_name, overall_label=\"Overall\"):\n",
    "    \"\"\"Return tidy dataframe: Year, Group, AAMR (mean if duplicates).\"\"\"\n",
    "    xls = pd.ExcelFile(path)\n",
    "    real_sheet = _resolve_sheet_name(xls, sheet_name)\n",
    "    df = pd.read_excel(xls, sheet_name=real_sheet)\n",
    "    df = _flatten_columns(df)\n",
    "\n",
    "    ycol = find_year(df)\n",
    "    tcol = find_aamr(df)\n",
    "    gcol = find_group(df)  # may be None\n",
    "\n",
    "    # SPECIAL: if 'Sex' exists anywhere, force it as group (ensures 'overall final' splits Male/Female).\n",
    "    sex_cols = [c for c in df.columns if _normalize_name(c) == \"sex\"]\n",
    "    if sex_cols:\n",
    "        gcol = sex_cols[0]\n",
    "\n",
    "    df[ycol] = pd.to_numeric(df[ycol], errors=\"coerce\")\n",
    "    df[tcol] = pd.to_numeric(df[tcol], errors=\"coerce\")\n",
    "\n",
    "    if gcol and gcol == tcol:\n",
    "        gcol = None\n",
    "\n",
    "    if gcol is None:\n",
    "        tidy = (df[[ycol, tcol]]\n",
    "                .dropna(subset=[ycol, tcol])\n",
    "                .groupby(ycol, as_index=False)[tcol].mean()\n",
    "                .rename(columns={ycol:\"Year\", tcol:\"AAMR\"}))\n",
    "        tidy[\"Group\"] = overall_label\n",
    "        tidy = tidy[[\"Year\",\"Group\",\"AAMR\"]]\n",
    "    else:\n",
    "        df[gcol] = df[gcol].astype(str).str.strip()\n",
    "        tidy = (df[[ycol, gcol, tcol]]\n",
    "                .dropna(subset=[ycol, gcol, tcol])\n",
    "                .groupby([ycol, gcol], as_index=False)[tcol].mean()\n",
    "                .rename(columns={ycol:\"Year\", gcol:\"Group\", tcol:\"AAMR\"}))\n",
    "\n",
    "    tidy[\"Year\"] = tidy[\"Year\"].astype(int)\n",
    "    tidy = tidy.sort_values([\"Group\",\"Year\"]).reset_index(drop=True)\n",
    "\n",
    "    # keep label to format y-axis later\n",
    "    tidy._aamr_label = _rate_axis_label_from_header(tcol)\n",
    "\n",
    "    print(f\"\\nSheet: {real_sheet}\")\n",
    "    print(f\"Detected â†’ Year: '{ycol}' | AAMR: '{tcol}' | Group: '{(gcol or overall_label)}'\")\n",
    "    print(tidy.head(6))\n",
    "    return tidy\n",
    "\n",
    "# ---------------- ARIMA + FORECAST ----------------\n",
    "def _sanitize_series_for_arima(y: pd.Series):\n",
    "    y = y.sort_index()\n",
    "    full = pd.Index(range(int(y.index.min()), int(y.index.max()) + 1), name=y.index.name)\n",
    "    y = y.reindex(full)\n",
    "    if y.isna().any():\n",
    "        y = y.interpolate(limit_direction=\"both\")\n",
    "    return y\n",
    "\n",
    "def select_arima_order(y):\n",
    "    best = None\n",
    "    for d in [0,1,2]:\n",
    "        for p in range(0,4):\n",
    "            for q in range(0,4):\n",
    "                if (p,d,q) == (0,0,0): \n",
    "                    continue\n",
    "                try:\n",
    "                    trend = \"n\" if d>0 else \"c\"\n",
    "                    res = ARIMA(\n",
    "                        y, order=(p,d,q), trend=trend,\n",
    "                        enforce_stationarity=False, enforce_invertibility=False\n",
    "                    ).fit(method_kwargs={\"warn_convergence\":False})\n",
    "                    score = res.aic\n",
    "                    if (best is None) or (score < best[0]):\n",
    "                        best = (score, (p,d,q,trend), res)\n",
    "                except Exception:\n",
    "                    pass\n",
    "    if best is None:\n",
    "        res = ARIMA(y, order=(1,1,0), trend=\"n\",\n",
    "                    enforce_stationarity=False, enforce_invertibility=False\n",
    "                   ).fit(method_kwargs={\"warn_convergence\":False})\n",
    "        return (1,1,0,\"n\"), res\n",
    "    return best[1], best[2]\n",
    "\n",
    "def forecast_to(y, end_year, conf=0.95):\n",
    "    last_year = int(y.index.max())\n",
    "    steps = max(0, end_year - last_year)\n",
    "    if steps == 0:\n",
    "        raise ValueError(\"Observed series already extends to END_YEAR.\")\n",
    "    order, res = select_arima_order(y)\n",
    "    fc = res.get_forecast(steps=steps)\n",
    "    mean = fc.predicted_mean\n",
    "    ci   = fc.conf_int(alpha=1-conf)\n",
    "    lo, hi = ci.iloc[:,0], ci.iloc[:,1]\n",
    "    yrs = list(range(last_year+1, end_year+1))\n",
    "    out = pd.DataFrame({\n",
    "        \"Year\": yrs,\n",
    "        \"Point.Forecast\": mean.values,\n",
    "        \"Lo.95\": lo.values,\n",
    "        \"Hi.95\": hi.values,\n",
    "        \"Order\": [f\"{order[0]},{order[1]},{order[2]} ({order[3]})\"]*steps\n",
    "    })\n",
    "    return order, out\n",
    "\n",
    "# ---------------- FIT, SAVE, PLOT ----------------\n",
    "def fit_all_groups_and_save(observed_df, end_year, out_dir: Path, title_prefix=\"Forecast\"):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    groups = sorted(observed_df[\"Group\"].unique())\n",
    "    all_rows = []\n",
    "    last_obs_year = int(observed_df[\"Year\"].max())\n",
    "    y_label = getattr(observed_df, \"_aamr_label\", \"AAMR\")\n",
    "\n",
    "    for g in groups:\n",
    "        sub = observed_df[observed_df[\"Group\"]==g].dropna(subset=[\"Year\",\"AAMR\"]).sort_values(\"Year\")\n",
    "        y = pd.Series(sub[\"AAMR\"].values, index=sub[\"Year\"].astype(int), name=\"AAMR\")\n",
    "        y = _sanitize_series_for_arima(y)\n",
    "\n",
    "        order, fc = forecast_to(y, end_year=end_year, conf=0.95)\n",
    "\n",
    "        # per-group CSV (2 decimals)\n",
    "        csv_path = out_dir / f\"{safe_name(g)}_forecast_to_{end_year}.csv\"\n",
    "        fc_out = fc.copy()\n",
    "        for c in [\"Point.Forecast\",\"Lo.95\",\"Hi.95\"]:\n",
    "            fc_out[c] = pd.to_numeric(fc_out[c], errors=\"coerce\").round(2)\n",
    "        fc_out.insert(0, \"Series\", g)\n",
    "        fc_out.to_csv(csv_path, index=False)\n",
    "        print(f\"[{g}] order={order}  -> CSV: {csv_path}\")\n",
    "\n",
    "        # store for consolidated\n",
    "        tmp = fc_out.copy(); tmp[\"Group\"] = g\n",
    "        all_rows.append(tmp)\n",
    "\n",
    "        # per-group plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(y.index, y.values, marker=\"o\", label=f\"{g} (obs)\")\n",
    "        ln, = ax.plot(fc[\"Year\"], fc[\"Point.Forecast\"], linestyle=\"--\", marker=\"o\", label=f\"{g} (fc)\")\n",
    "        ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.14, color=ln.get_color(), label=\"95% CI (fc)\")\n",
    "        ax.axvline(x=last_obs_year+0.5, linestyle=\":\", linewidth=2.0)\n",
    "        ax.set_title(f\"{title_prefix}: {g} â€” observed (â‰¤{last_obs_year}) & ARIMA forecast ({last_obs_year+1}â€“{end_year})\")\n",
    "        ax.set_xlabel(\"Year\"); ax.set_ylabel(y_label)\n",
    "        ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n",
    "        style_axes(ax)\n",
    "        ax.legend(ncols=2)\n",
    "        plt.tight_layout()\n",
    "        png_path = out_dir / f\"{safe_name(g)}_timeseries_to_{end_year}.png\"\n",
    "        plt.savefig(png_path, dpi=300, bbox_inches=\"tight\"); plt.close()\n",
    "        print(\"   Plot:\", png_path)\n",
    "\n",
    "    if all_rows:\n",
    "        all_df = pd.concat(all_rows, ignore_index=True)\n",
    "        all_df.to_csv(out_dir / f\"ALL_GROUPS_forecasts_to_{end_year}.csv\", index=False)\n",
    "        print(\"Consolidated CSV:\", out_dir / f\"ALL_GROUPS_forecasts_to_{end_year}.csv\")\n",
    "\n",
    "def plot_combined(observed_df, out_dir:Path, end_year:int, title=\"Forecast\", top_n=None):\n",
    "    last_obs_year = int(observed_df[\"Year\"].max())\n",
    "    groups = sorted(observed_df[\"Group\"].unique())\n",
    "    y_label = getattr(observed_df, \"_aamr_label\", \"AAMR\")\n",
    "\n",
    "    # read saved forecasts\n",
    "    fc_map = {}\n",
    "    for g in groups:\n",
    "        p = out_dir / f\"{safe_name(g)}_forecast_to_{end_year}.csv\"\n",
    "        if p.exists():\n",
    "            fc_map[g] = pd.read_csv(p)\n",
    "\n",
    "    # limit to top N (if requested)\n",
    "    if top_n is not None and len(groups) > top_n:\n",
    "        latest = (observed_df.sort_values(\"Year\")\n",
    "                  .groupby(\"Group\", as_index=False)\n",
    "                  .apply(lambda d: d.iloc[-1][[\"Group\",\"AAMR\"]])\n",
    "                  .reset_index(drop=True))\n",
    "        keep = (latest.sort_values(\"AAMR\", ascending=False)\n",
    "                      .head(top_n)[\"Group\"].tolist())\n",
    "        groups = [g for g in groups if g in keep]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ci_legend_added = False\n",
    "\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key().get('color', None)\n",
    "    color_map = {}\n",
    "    if colors:\n",
    "        for i, g in enumerate(groups):\n",
    "            color_map[g] = colors[i % len(colors)]\n",
    "\n",
    "    for g in groups:\n",
    "        sub = observed_df[observed_df[\"Group\"]==g].copy().sort_values(\"Year\")\n",
    "        kw_obs = {\"marker\": \"o\", \"label\": f\"{g} (obs)\"}\n",
    "        if g in color_map: kw_obs[\"color\"] = color_map[g]\n",
    "        ax.plot(sub[\"Year\"], sub[\"AAMR\"], **kw_obs)\n",
    "\n",
    "        if g in fc_map:\n",
    "            fc = fc_map[g]\n",
    "            kw_fc = {\"linestyle\": \"--\", \"marker\": \"o\", \"label\": f\"{g} (fc)\"}\n",
    "            if g in color_map: kw_fc[\"color\"] = color_map[g]\n",
    "            ln, = ax.plot(fc[\"Year\"], fc[\"Point.Forecast\"], **kw_fc)\n",
    "            if not ci_legend_added:\n",
    "                ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.12,\n",
    "                                color=ln.get_color(), label=\"95% CI (fc)\")\n",
    "                ci_legend_added = True\n",
    "            else:\n",
    "                ax.fill_between(fc[\"Year\"], fc[\"Lo.95\"], fc[\"Hi.95\"], alpha=0.12,\n",
    "                                color=ln.get_color())\n",
    "\n",
    "    ax.axvline(x=last_obs_year+0.5, linestyle=\":\", linewidth=2.0)\n",
    "    ax.set_title(f\"{title}: observed (â‰¤{last_obs_year}) & ARIMA forecast ({last_obs_year+1}â€“{end_year})\")\n",
    "    ax.set_xlabel(\"Year\"); ax.set_ylabel(y_label)\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.2f\"))\n",
    "    style_axes(ax)\n",
    "    ax.legend(ncols=2)\n",
    "    ax.margins(x=0.02)\n",
    "    plt.tight_layout()\n",
    "    out = out_dir / f\"COMBINED_timeseries_to_{end_year}.png\"\n",
    "    plt.savefig(out, dpi=300, bbox_inches=\"tight\"); plt.close()\n",
    "    print(\"Combined plot:\", out)\n",
    "\n",
    "# ---------------- RUN ALL SHEETS ----------------\n",
    "for sheet_name, folder, pretty_title in RUN_SHEETS:\n",
    "    out_dir = OUTPUT_BASE / folder\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    observed = load_observed_excel(FILE_PATH, sheet_name=sheet_name, overall_label=\"Overall\")\n",
    "    fit_all_groups_and_save(observed, END_YEAR, out_dir, title_prefix=pretty_title)\n",
    "\n",
    "    topn = TOP_N_FOR_COMBINED.get(folder)\n",
    "    plot_combined(observed, out_dir, END_YEAR, title=pretty_title, top_n=topn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f63594b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
